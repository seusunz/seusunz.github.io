[{"title":"Hello World","url":"/2025/10/27/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"},{"title":"深度解析H.266/VVC 熵编码CABAC","url":"/2024/08/14/深度解析H-266-熵编码CABAC/","content":"\n\n\n# 1.熵编码 \n\n## 1.1 研究背景\n\n数据压缩技术的理论基础就是**信息论**。信息论中的信源编码理论解决的主要问题：\n（1）数据压缩的理论极限；\n（2）数据压缩的基本途径。\n根据信息论的原理，可以找到最佳数据压缩编码的方法。数据压缩的理论极限是**信息熵**。信息熵为信源的平均信息量（不确定性的度量）。\n\n如果要求编码过程中不丢失信息量，即要求保存信息熵，这种信息保持编码叫**熵编码**，是根据消息出现概率的分布特性而进行的，是无损数据压缩编码。因此，熵编码即编码过程中按熵原理不丢失任何信息的编码。\n\n## 1.2 常见的熵编码\n\n在视频编码中，熵编码把一系列用来**表示视频序列的元素符号**转变为一个用来**传输或是存储的压缩码流**。输入的符号可能包括量化后的变换系数，运动向量，头信息（宏块头，图象头，序列的头等）以及附加信息（对于正确解码来说重要的标记位信息）。\n\n常见的熵编码有：\n\n1. 香农(Shannon)编码\n\n2. 哈夫曼(Huffman)编码 \n3. 算术编码(arithmetic coding)\n4. 行程编码 （RLE） \n5. 基于上下文的自适应变长编码（CAVLC） \n6. 基于上下文的自适应二进制算术编码（CABAC）\n\n熵编码一个很重要的应用领域就是图像压缩。\n下面是JPEG的编码流程。蓝色框中的编码就是用了熵编码。\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/16d8e98e5d1aa56f2122a86ba4792490.png)\n\n至于其他的视频标准，如MPEG2，H264, H265，编码流程都是大同小异，过程无非都是采样-DCT-量化-编码。它们都会用到**熵编码**，例如**JPEG用的是Huffman编码和算术编码，H264用的是CAVLC和CABAC**。\n\n\n\n# 2.熵编码类型\n\n## 2.1 CABAC\n\n**CABAC编码的目的是从概率的角度再做一次压缩，编码的过程主要分为二值化，上下文建模，二进制算术编码。**\n\n基于上下文的二进制算术编码（Context-Based Adaptive Binary Arithmetic Coding,CABAC）将自适应二进制算术编码和上下文模型相结合，是H.265/HEVC的主要熵编码方案。主要包括三个步骤：\n1.二进制化；\n2.上下文建模；\n3.二进制算术编码；\n其流程如下：\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/b84aa1b83f8a041a057e3de70f00195b.png)\n\n**1.二值化**\n\n​\t    在图像处理世界中，所谓二值化就是将像素点的值根据一定的算法，将像素分别修改为0，或255，即获取图像的灰度图，或者通俗些讲就是图像的黑白图。而此处的“二值化”可以暂且理解为，将数值二进制化的一个过程，当然不是简单的将十进制转换为二进制。CABAC中二值化的方式主要有“一元码”，“截断一元码”，“K阶指数哥伦布编码”，“定长编码”，详细的就不展开了，不过小编决定了后续专门搞篇说这个的，嫑着急。这里简单以“一元码”简单举例说明下：\n\n​       “一元码”的编码方式是，对于一个非二进制的无符号整数x >= 0，在CABAC中的一元码码字用x个“1”位外再加一个“0”组成。For example，   对“8”编码，则二值化后的结果为“111111110”。辣么，如果是6呢，你可以尝试一下的哦。\n\n​       经过二值化之后，CABAC就已经把待编码的语法元素按照一定的规则转换为只用“0”和“1”的二进制流，称为比特流。\n\n**2.上下文编码**\n\n​        待编码数据具有上下文相关性，利用已编码数据提供的上下文信息，为待编码的数据选择合适的概率模型，这就是上下文建模。通过对上下文模型的构建，基本概率模型能够适应随视频图像而改变的统计特性，降低数据之间的冗余度，并减少运算开支。\n\n​        H.264/AVC标准将一个Slice可能出现的数据划分为399个上下文模型，每个模型均有自己的上下文序号，命名为CtxIdx，每个不同的字符依据对应的上下文模型，来索引自身的概率查找表。即收到字符后，先找到字符对应的上下文模型的序号CtxIdx，然后根据CtxIdx找到其对应的概率查找表。 详细的步骤如下：\n\n​       确定当前的字符对应的上下文模型的区间，H264标准中的表9-1描述了相应的对应关系。\n\n![image-20241204225148211](C:\\Users\\sun\\AppData\\Roaming\\Typora\\typora-user-images\\image-20241204225148211.png)\n\n​\t 按照不同的法则，在（1）步中得到的区间中最终确定的上下文模型个的CtxIdx。具体的法则同样需要去查找标准里对应的一些表，在此就不再赘述。\n\n**3.二进制算术编码**\n\n​\t  第三步通过上下文建模找到的概率模型的概率估计方法构成了一个自适应二进制算术编码器。概率估计是在前一次上下文建模阶段更新后的概率估计。在对每个二进制数值编码过后，概率估计的值相应的也会根据刚刚编码的二进制符号进行调整。\n\n​      二进制算术编码是算术编码的特殊情况，其原理与一般算术编码一样（关于算术编码，大家可自行查阅，当然，小编也准备单开一篇缕缕喽）。不同的是，二进制算术编码序列只有“0”和“1”两种符号，所涉及的概率也只有P(0)和P(1)。\n\n​      经过上述的步骤，同样也就经历了一次熵编码的完整过程，即CABAC的大概流程，由于细节部分涉及的内容相对较多，后续慢慢研究喽。希望对大家有所帮助哦。\n\n\n\n\n\n","tags":["vvc"],"categories":["developer"]},{"title":"深度解析H.266/VVC环路滤波","url":"/2024/07/29/深度解析H-266-环路滤波/","content":"\n# 一、环路滤波基础\n\n定义：在视频编码过程中进行滤波，滤波后的图像用于后续编码。\n目的：\n- 提升编码图像的质量。\n- 为后续编码图像提供高质量参考，获得更好的预测效果。\n\nVVC中主要采取的技术有：\n- 色度与亮度缩放（Luma Mapping Chroma Scaling, LMCS）、\n- 去方块滤波（De-Blocking Filter, DBF）、\n- 样点自适应补偿（Sample Adaptive Offset, SAO）、\n- 自适应滤波（Adaptive Loop Filter, ALF）。\n\nDBF用于降低方块效应、SAO用于改善振铃效应、ALF可以减少解码误差。\n在编码环路中，一般是先去方块滤波、样点自适应补偿和自适应环路滤波的顺序。LMCS一般对编码前的图像进行预处理。\n\n# 二、环路滤波方法\n## 2.1 色度与亮度缩放（LMCS）\n### 2.2.1 背景\n包括两个部分：\n- 基于自适应分段线性模型的亮度映射；应用在像素级，利用亮度值范围及广电转换特性来提高视频的编码效率。\n- 基于亮度的色度残差缩放：应用在色度块级，通过补偿亮度信号映射对色度信号的影响。\n\n解码端LMCS框架结构如下图所示：\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/81160951c7194651afa853c81f839cdb.png)\n\n### 2.2.2 VVC 中的亮度/色度缩放\n**基本思想**\n\t\t在指定的位深下更好地使用允许的亮度值范围。10bit视频亮度值范围为[64,940]。在编解码过程中，前向映射将范围[64,940]映射到[0,1023]中，再进行变换、量化等模块的处理。或者一个亮度范围较小的视频，没有充分利用允许的亮度值，因此LMCS就是将原始域亮度值映射到允许的亮度值范围。\n\n**基于分段线性模型的亮度映射**\n\t\tVVC中，前向映射函数FwdMap使用一个分段线性模型，反向映射函数InvMap为逆函数。\n\t\t根据视频的位深将原始域的码值范围划分为16个相等的片段，每个片段的码字数量由OrgCW表示，\n\t\t变量InputPivot[i]表示原始域内各片段的边界点。\n\t\t有InputPivot[i] = i * OrgCW;\n\t\t映射域内各片段的边界点表示MappedPivot[i]，\n\t\tMappedPivot[i+1]-MappedPivot[i]的值就是映射域中第i个片段的亮度值个数，表示为SignalledCW[i]。\n\n**色度缩放**\n\t\t前向缩放将原始域色度值转换到映射域，有色度缩放以TU为单位，同一个TU使用相同的缩放因子，也使用分段线性模型，同一个片段色度缩放因子相同。色度缩放偏移量deltaCRS由自适应参数集LMCS_APS标识。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a7239aebc9f040cc8d5f1927014b3391.png)\n\n\n\n**LMCS的实现**\n\t\t介绍的是VTM中使用的LMCS模型参数的构建方法，对于SDR\\HDR-PQ\\HDR-HLG视频的特性不同，模型参数不同。对于SDR和HDR-HLG视频，基于局部亮度方差，针对PSNR指标进行优化。对于HDR-PQ视频，针对加权PSNR进行优化，基本思想为空间平滑区域分配相比复杂区域更多的码字。\n\n**SDR\\HDR-HLG视频**\n1、统计分析视频内容，在原始域划分片段，分配初始码字\n2、根据图像内容调整片段的码字数量\n3、如果分配的码字总数大于允许的最大码字数，从第一个片段开始，每个片段减少相同的数量，知道妈祖条件，得到最终每个片段分配的码字数量SignalledCW[i].\n4、根据亮度样本映射前后的相对值及平均局部方差，确定LMCS片类型、高码率自适应和色度调整自适应参数。\n\n**HDR-PQ视频**\n1、计算映射模型曲线的斜率\n2、积分映射模型曲线的斜率\n3、归一化\n4、计算每个片段的码字数量。\n\n**LMCS的相关语法元素**\n**SPS层**\n\n|        变量名         |         含义          |\n| :-------------------: | :-------------------: |\n| sps_lmcs_enabled_flag | 为1的时候标识使用LMCS |\n\n**PH层**\n\n|            变量名             |                             含义                             |\n| :---------------------------: | :----------------------------------------------------------: |\n|     ph_lmcs_enabled_flag      |                     当前图像是否使用LMCS                     |\n|        ph_lmcs_aps_id         | 当前按图片中的slice所应用的LMCS APS的aps_adaptation_parameter_set_id |\n| ph_chroma_residual_scale_flag |                 当前图片是否使用色度残差缩放                 |\n\n**SH层**\n\n|      变量名       |         含义          |\n| :---------------: | :-------------------: |\n| sh_lmcs_used_flag | 当前slice是否使用LMCS |\n\n**APS层**\n\n|           变量名           |                含义                 |\n| :------------------------: | :---------------------------------: |\n|      lmcs_min_bin_idx      |     LMCS过程中使用的最小bin索引     |\n|   lmcs_delta_max_bin_idx   |      最大bin索引与15之间的差值      |\n| lmcs_delta_cw_prec_minus1  | 加1用于kmcs_delta_abs_cw[i]的比特数 |\n|    lmcs_delta_abs_cw[i]    |      第i个区间的码字绝对增量值      |\n| lmcs_delta_sign_cw_flag[i] |    标识变量LmcsDeltaCW[i]的符号     |\n|     lmcs_delta_abs_crs     |  表示变量LmcsDeltaCrs的绝对码字值   |\n|  lmcs_delta_sign_crs_flag  |     表示变量LmcsDeltaCrs的符号      |\n\n\n## 2.2 去方块滤波（DBF）—减轻块效应\n### 2.2.1 背景\n目前主流的视频编码标准都是基于分块的混合编码机制，其处理过程是针对每个块单独进行处理的，因此由于编码模式的差异以及量化误差的原因，会导致相邻块重建像素不连续的现象。对于一个两侧强相关性的块边界，当图像较平滑时，就会在重建图像中出现方块效应，如下图所示。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3c59fe17522549ae86842a1153508ab6.png)\n方块效应产生的原因主要包括以下两个方面：\n\n1. 由变换、量化的误差引起的。在视频编码中，量化是一个有损压缩过程，因此在反量化、反变换之后的重建图像会出现误差，由于不同块之间的处理不一致，而且边界处的误差格外大一些，会造成图像在边界上的视觉不连续。\n2. 来自帧间的运动补偿过程。对于相邻块，其运动补偿的预测数据可能来自同一帧的不同位置、不同帧不同的位置，因此会产生误差，引起图像在复制的边界上的不连续现象。\n\n为了消除或者减轻块效应，通常使用去块滤波（DBF）修正图像边界处的像素值。\n### 2.2.2 VVC 中的去块滤波\nVVC中与HEVC的去块滤波过程类似。在VVC中，对CU边界、变换子块边界和预测子块边界进行去块滤波处理。预测子块边界包括由SbTMVP和仿射模式引入的预测单元PU边界，变换子块边界包括由SBT和ISP模式引入的变换单元边界，以及由于大CUs的隐式划分而引起的变换。对CU边界和变换子块边界采用4x4滤波处理网格，对预测子块边界采用8x8滤波处理网格。对于SBT和ISP子块，类似于HEVC去块滤波器中TU的逻辑，当任一变换子块的边缘有非零系数时，在TU边界上应用去块滤波器。对于SbTMVP和仿射预测子块，类似于HEVC中PU中的逻辑，在8x8网格上应用去块滤波器，同时考虑相邻预测子块的运动矢量和参考图片之间的差异。变换块边界最多可以用变换边界一侧的5个样本去块，变换边界也是编码块的一部分，其中SbTMVP或affine用于实现并行友好去块。内部预测子块边界来自变换块边界的4个样本在每侧最多滤波1个样本，内部预测子块边界远离变换块边界的8个样本在边界的每侧最多滤波2个样本，并且其他内部预测子块边界在边界的每侧最多滤波3个样本。\n\n针对亮度滤波，VVC对“大块”引入了双线性滤波器（更强滤波），“大块”即边界长度大于等于32的块。亮度分量的滤波器分类如下：\n\n- 更强滤波，最多可达每侧边界的7个像素\n- 强滤波，对边界像素每边修改3个像素\n- 弱滤波，最多对边界两边修改2个像素\n\n由于VVC的二叉树、三叉树划分引入矩形块，所以VVC中亮度使用4x4大小的滤波处理单元。\n\n针对色度滤波，主要分为以下两种滤波器：\n\n- 强滤波，对边界每边修改3个像素\n- 弱滤波，对边界每侧修改1个像素\n- 色度滤波仅使用8x8的滤波处理单元。\n\n以8x8滤波处理单元为例，每个处理块横跨4个8x8的呈“+”字形的边界， 如下图所示，\n边界两侧块分别用P（垂直边界左侧块或者水平边界上侧块）和Q（垂直边界右侧块和水平边界下侧块）表示。\n对于需要滤波的边界，按照先亮度分量后色度分量的顺序；\n对于同一分量的块，按照先垂直边界后水平边界的顺序。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6d887da96c374a6185c1b06bdbc9385a.png)\nVVC的去块滤波过程和HEVC的类似，主要包含三个步骤\n\n- 根据边界两侧的编码模式和编码参数确定边界强度\n- 根据边界两侧像素值，确定滤波强度（包括滤波开关决策和滤波强度决策）\n- 进行滤波处理过程\n\n\n## 2.3 样点自适应补偿（SAO）—改善振铃效应\n### 2.3.1 背景\n### 2.3.2 VVC 中的样点自适应补偿\n\n\n## 2.4 自适应滤波（ALF）—减少解码误差\n### 2.4.1 背景\n自适应环路滤波（ALF）并不是在 H.266/VVC 标准制定过程中才被提出来的技术，实际上其早在 H.265/HEVC 标准制定时就基本确定了现有形式的雏形，只是由于当时硬件算力的限制未能加入到 HEVC 标准中。详细可阅读以下的论文。随着硬件算力的提升与一些优化方法的提出，以及人们对更高效率的编解码算法的期望，ALF 自然就成了 VVC 标准中不可或缺的部分。由于 ALF 是一个十分有效的手段，也就吸引力不少人去研究，很多率失真改进方法不断被提出，所以基本每一次会议之后都能看到一些不同的地方。这里我主要就其滤波的原理进行介绍，这些目前在网上的资料是比较少的，也可以让大家能够更好地理解 VTM 代码里的相关实现。\n\nALF 模块处于去块效应滤波（Deblocking Filtering, DF）和样点自适应补偿（Sample Adaptive Offset, SAO）之后。相比于 DF 和 SAO，ALF 更加贴近于我们对图像滤波的一般理解，也就是说其可以表示为图像与卷积核之间的卷积运算。而至于所使用卷积核，当然不是什么高斯模糊、边缘检测之类的，视频编解码算法里降低码率和误差才是王道。靠滤波来直接降低码率自然是不行的，那是熵编码干的活，那什么滤波可以降低误差呢？没错，就是维纳滤波（Wiener Filtering, WF）。\n\n维纳滤波是一种基于最小均方误差准则、对平稳过程的最优估计器，其输出与期望输出之间的均方误差为最小。然而，要注意的是，维纳滤波并不是一种现成的滤波器，其只是确立了一种准则，具体还是要自己设计的，在信号与系统里也就是找到相应的系统冲激响应，在离散图像里也就是要找到相应的卷积核。因此，下面的内容将就该卷积核的求导进行详细的介绍。\n\n\n### 2.4.2 VVC 中的自适应滤波 alf\n**1. 滤波器的形状**\n虽然维纳滤波并没有限制所用的滤波器形式，但我们还是要综合考虑其实现的难度以及所能带来的增益。在图像处理中，最方便、直观的滤波方式就是采用一个矩形的卷积核，ALF 也遵循这种习惯。不过，很显然，卷积核的尺寸越大，所获得的增益一般来说会越大，但其所带来的计算复杂度也就越高，而且这种增益和复杂度之间的关系并不是线性的。\n\n另外，维纳滤波是和原始数据相关的，而解码端是不可能接触到原始数据的，那就意味着我们必须要把解码端所求得的滤波系数编到码流中进行传输，所以我们也不能把卷积核弄得太大。\n\n考虑以上因素，VVC  定义了两种形状的滤波器，其中对亮度分量使用 7x7 的滤波器，而对色度分量采用 5x5 的滤波器。\n\n为了减少传输滤波器系数的码字以及降低滤波的计算复杂度，ALF 使用了菱形且中心对称的滤波系数矩阵，其形状如图 1 所示，也就是只有菱形内的像素会参与滤波，而中心对称的像素使用相同的滤波系数，其中滤波器中心的位置即是当前滤波的像素位置。\n\n对于亮度分量，VVC定义了最多 25 组滤波系数，像素所属分组基于重建后的图像以 4x4 小块为单位，根据该块以及周围像素的梯度信息进行推导，该块内所有像素均属于同一组。\n\n对于色度分量，Cb，Cr 各自只定义一组系数。\n\n三个分量独立进行率失真优化与系数推导以及最终的滤波。具体亮度分量像素的分类在标准文档中有详细介绍，这里不多说。\n\n```c++\nenum AlfFilterType\n{\n  ALF_FILTER_5,\n  ALF_FILTER_7,\n  ALF_NUM_OF_FILTER_TYPES\n};\n```\n\n\n\n![ALF filter shapes](https://i-blog.csdnimg.cn/direct/64c46451e9b6487aaee98202746a806e.png)\n\n**2. 维纳滤波**\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/cf0b25857d0c41c2a65bc085143cea51.png)\n将上式写成矩阵形式，可得\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/468171e9cd9c499cb541ef33ac0a8e05.png)\n为了方便，我们令\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e1701a0162ac4b83b2baf82448f5789d.png)\n那么上面的线性方程组可写为\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/2baf26840eb64dcd9aace4179cab9eb5.png)\n其中\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5f30a6d1fc5c4f469a3cebfe6d714aba.png)\n\n### 3. 块分类\n\n**注意**：对不同的小块使用不同的滤波器，因此需将这些小块进行分类，以区分出小块要使用的滤波器是哪一种。\n\n\n\n对于亮度分量需要为每个4x4的子块分类，共25个类别C。类别C是由4x4块的方向D和活动性A决定：\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tC = 5D + A\n其中D和A分别表示当前块的Direction和Activity；\n\n计算之前需要先用1-D拉普拉斯算子计算当前块的水平、垂直和两个对角方向的gradient。为了计算D和A，需要计算子块的水平、垂直、两个对角线方向的梯度。梯度计算使用一维拉普拉斯方法实现：\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/ef65add47c934cd9a646d00c299c4b29.png)\n为了减少计算复杂度，在计算梯度前，进行一维拉普拉斯计算下采样，如下图：\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/0c1eba37c2dd47b99dd9824d2f4ed3f8.png)\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5e8b63e653594dbba15ee28b748ba10f.png)\n因此，计算4x4块类别C的步骤为：\n\n1. 首先进行图像下采样，计算水平gh和垂直gv方向的梯度；\n2. 其次，根据gh和gv计算gmax(h,v)和gmin(h,v),得到D和A：\n3. 然后将D和A代入类别C=5D + A计算公式,计算出亮度4x4块的类别C, 从而选定4x4小块的滤波器参数类别组\n4. 对于色度分量不需要对其子块进行分类操作，它只有一个滤波器。\n\n\n### 4. 滤波器系数和门限值几何变换\n由上一步可以得到滤波器，但是在滤波操作前需要对滤波器系数和相应门限值进行几何变换，包括旋转、对角和垂直翻转。\n\n变换类型由上面计算的块的梯度决定。\n\n对滤波器进行几何变换效果等价于对滤波区域进行相应几何变换，这么做的目的是使不同块方向对齐。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/d628ce65bb6d40588305e93ff7410ee1.png)\n\n```c++\n  if( filtType == ALF_FILTER_7 )\n      {\n        if( transposeIdx == 1 )\n        {//!<对角线变换\n          filterCoeff = { coef[9], coef[4], coef[10], coef[8], coef[1], coef[5], coef[11], coef[7], coef[3], coef[0], coef[2], coef[6], coef[12] };\n#if JVET_N0242_NON_LINEAR_ALF\n          filterClipp = { clip[9], clip[4], clip[10], clip[8], clip[1], clip[5], clip[11], clip[7], clip[3], clip[0], clip[2], clip[6], clip[12] };\n#endif\n        }\n        else if( transposeIdx == 2 )\n        {//!<垂直翻转\n          filterCoeff = { coef[0], coef[3], coef[2], coef[1], coef[8], coef[7], coef[6], coef[5], coef[4], coef[9], coef[10], coef[11], coef[12] };\n#if JVET_N0242_NON_LINEAR_ALF\n          filterClipp = { clip[0], clip[3], clip[2], clip[1], clip[8], clip[7], clip[6], clip[5], clip[4], clip[9], clip[10], clip[11], clip[12] };\n#endif\n        }\n        else if( transposeIdx == 3 )\n        {//!<旋转变换\n          filterCoeff = { coef[9], coef[8], coef[10], coef[4], coef[3], coef[7], coef[11], coef[5], coef[1], coef[0], coef[2], coef[6], coef[12] };\n#if JVET_N0242_NON_LINEAR_ALF\n          filterClipp = { clip[9], clip[8], clip[10], clip[4], clip[3], clip[7], clip[11], clip[5], clip[1], clip[0], clip[2], clip[6], clip[12] };\n#endif\n        }\n        else\n        {//!<不变换\n          filterCoeff = { coef[0], coef[1], coef[2], coef[3], coef[4], coef[5], coef[6], coef[7], coef[8], coef[9], coef[10], coef[11], coef[12] };\n#if JVET_N0242_NON_LINEAR_ALF\n          filterClipp = { clip[0], clip[1], clip[2], clip[3], clip[4], clip[5], clip[6], clip[7], clip[8], clip[9], clip[10], clip[11], clip[12] };\n#endif\n        }\n      }\n      else\n      {\n        if( transposeIdx == 1 )\n        {//!<对角线变换\n          filterCoeff = { coef[4], coef[1], coef[5], coef[3], coef[0], coef[2], coef[6] };\n#if JVET_N0242_NON_LINEAR_ALF\n          filterClipp = { clip[4], clip[1], clip[5], clip[3], clip[0], clip[2], clip[6] };\n#endif\n        }\n        else if( transposeIdx == 2 )\n        {//!<垂直翻转\n          filterCoeff = { coef[0], coef[3], coef[2], coef[1], coef[4], coef[5], coef[6] };\n#if JVET_N0242_NON_LINEAR_ALF\n          filterClipp = { clip[0], clip[3], clip[2], clip[1], clip[4], clip[5], clip[6] };\n#endif\n        }\n        else if( transposeIdx == 3 )\n        {//!<旋转变换\n          filterCoeff = { coef[4], coef[3], coef[5], coef[1], coef[0], coef[2], coef[6] };\n#if JVET_N0242_NON_LINEAR_ALF\n          filterClipp = { clip[4], clip[3], clip[5], clip[1], clip[0], clip[2], clip[6] };\n#endif\n        }\n        else\n        {//!<不变换\n          filterCoeff = { coef[0], coef[1], coef[2], coef[3], coef[4], coef[5], coef[6] };\n#if JVET_N0242_NON_LINEAR_ALF\n          filterClipp = { clip[0], clip[1], clip[2], clip[3], clip[4], clip[5], clip[6] };\n#endif\n        }\n```\n\n\n\n\n\n采用的几何变换方式由上面计算的四个方向的梯度决定：![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/169d2ef3cacc4e0fad8ae287c67ed51f.png)\n\n```c++\n   int hv1, hv0, d1, d0, hvd1, hvd0;\n​\n      if( sumV > sumH )\n      {\n        hv1 = sumV;\n        hv0 = sumH;\n        dirTempHV = 1;\n      }\n      else\n      {\n        hv1 = sumH;\n        hv0 = sumV;\n        dirTempHV = 3;\n      }\n      if( sumD0 > sumD1 )\n      {\n        d1 = sumD0;\n        d0 = sumD1;\n        dirTempD = 0;\n      }\n      else\n      {\n        d1 = sumD1;\n        d0 = sumD0;\n        dirTempD = 2;\n      }\n      if( d1*hv0 > hv1*d0 )\n      {\n        hvd1 = d1;\n        hvd0 = d0;\n        mainDirection = dirTempD;\n        secondaryDirection = dirTempHV;\n      }\n      else\n      {\n        hvd1 = hv1;\n        hvd0 = hv0;\n        mainDirection = dirTempHV;\n        secondaryDirection = dirTempD;\n      }\n​\n      int directionStrength = 0;\n      if( hvd1 > 2 * hvd0 )\n      {\n        directionStrength = 1;\n      }\n      if( hvd1 * 2 > 9 * hvd0 )\n      {\n        directionStrength = 2;\n      }\n​\n      if( directionStrength )\n      {\n        classIdx += ( ( ( mainDirection & 0x1 ) << 1 ) + directionStrength ) * 5;\n      }\n      //!<几何变换索引计算\n      static const int transposeTable[8] = { 0, 1, 0, 2, 2, 3, 1, 3 };\n      int transposeIdx = transposeTable[mainDirection * 2 + ( secondaryDirection >> 1 )];\n```\n\n\n\n### 5. 滤波器参数传输\n在VTM5中，ALF滤波器参数在Adaptation Parameter Set (APS)中。\n在一个APS中，有至多25组亮度滤波器参数和门限值，及至多1组色度滤波器参数和门限值。为了减少比特开销，不同类别的滤波器参数可以merge合并。当前slice使用的APS索引在slice header中。\n\nAPS中可以解码出门限值索引，通过门限值索引可以从亮度门限值列表和色度门限值列表中指定所需的门限值。门限值列表由位深决定：\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/d17b24784acc4ae8bcad0fc6a8099114.png)\n滤波过程可以在CTU级进行控制，可以传输一个标志位表示是否需要对一个亮度CTU进行ALF滤波。一个亮度CTU使用的滤波器可以从16个固定滤波器和APS提供的滤波器中选择。有一个滤波器索引表示最终使用的滤波器。16个固定滤波器是预定义好的，硬编码进编码器和解码器了。\n\n滤波器参数被量化成均值为128。为了减少乘法的复杂性，需要对码流进行一致性处理以使非中心位置的参数在[-128,127]间。中心位置的参数不需要传输，默认等于128。\n\n### 6. 滤波操作\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/52a16c0b82b94d4a960edd71af647a1b.png)","tags":["vvc"],"categories":["developer"]},{"title":"站在命运的十字路口","url":"/2024/07/21/站在命运的十字路口/","content":"\n\n\n# \n\n\n\n\n\n","tags":["life"],"categories":["mylife"]},{"title":"Hexo搭建个人博客网站记录","url":"/2024/07/21/hexo搭建个人博客网站记录/","content":"\n\n\n花了2天搭建了个网站，先上链接，欢迎来访：[九天之遥](https://seusunz.github.io) 现在市面上的博客很多，如CSDN，博客园，简书等平台，可以直接在上面发表，用户交互做的好，写的文章百度也能搜索的到。缺点是比较不自由，会受到平台的各种限制和恶心的广告。\n\n而自己购买域名和服务器，搭建博客的成本实在是太高了，不光是说这些购买成本，单单是花力气去自己搭这么一个网站，还要定期的维护它，对于我们大多数人来说，实在是没有这样的精力和时间。\n\n那么就有第三种选择，直接在github page平台上托管我们的博客。这样就可以安心的来写作，又不需要定期维护，而且hexo作为一个快速简洁的博客框架，用它来搭建博客真的非常容易。\n\n <!--more--> \n\n# 一、基本环境安装\n\nHexo是一款基于Node.js的静态博客框架，依赖少易于安装使用，可以方便的生成静态网页托管在GitHub和Coding上，是搭建博客的首选框架。大家可以进入hexo官网进行详细查看，因为Hexo的创建者是台湾人，对中文的支持很友好，可以选择中文进行查看。\n\n教程分三个部分，\n\n第一部分：hexo的初级搭建还有部署到github page上，以及个人域名的绑定。\n第二部分：hexo的基本配置，更换主题，实现多终端工作，以及在coding page部署实现国内外分流\n第三部分：hexo添加各种功能，包括搜索的SEO，阅读量统计，访问量统计和评论系统等。\n\nhexo的初级搭建还有部署到github page上，以及个人域名的绑定。\n\n## Hexo 搭建与部署到github page\n\n- 安装windows的Git\n\n- 安装Node.js\n\n- 安装Hexo\n\n- GitHub创建个人仓库\n\n- 生成SSH添加到GitHub\n\n- 将hexo部署到GitHub\n\n- 设置个人域名\n\n- 发布文章\n\n  ## 1.1 安装git\n\n  **windows**：到git官网上下载,[Download git](https://gitforwindows.org/),下载后会有一个Git Bash的命令行工具，以后就用这个工具来使用git。\n\n  **linux**：对linux来说实在是太简单了，因为最早的git就是在linux上编写的，只需要一行代码\n\n  ```cpp\n  sudo apt-get install git\n  ```\n\n  安装好后，用`git --version` 来查看一下版本\n\n  ## 1.2 安装Node.js\n\n  Hexo是基于nodeJS编写的，所以需要安装一下nodeJs和里面的npm工具。\n\n  **windows**：[nodejs](https://nodejs.org/en/download/)选择LTS版本就行了。在git安装完后，就可以直接使用git bash来敲命令行了\n\n  **linux**: 执行命令\n\n  ```cpp\n  sudo apt-get install nodejs\n  sudo apt-get install npm\n  ```\n\n  安装之后执行,检查一下有没有安装成功\n\n  ```\n  node -v\n  npm -v\n  ```\n\n  ## 1.3 安装Hexo\n\n  前面git和nodejs安装好后，就可以安装hexo了，你可以在本地合适的位置创建一个文件夹blog，然后`cd`到这个文件夹下（或者在这个文件夹下直接右键git bash打开）。\n\n  输入命令\n\n  ```cpp\n  npm install -g hexo-cli\n  ```\n\n  输入命令，查看版本\n\n  ```cpp\n  hexo -v\n  ```\n\n  至此安装完毕。初始化hexo\n\n  ```cpp\n  hexo init myblog\n  ```\n\n  进入创建的目录，安装npm\n\n  ```cpp\n  cd myblog //进入这个myblog文件夹\n  npm install\n  ```\n\n  安装完成后，指定目录下会存在一下文件：\n\n  - node_modules: 依赖包\n\n  - public：存放生成的页面\n  - scaffolds：生成文章的一些模板\n  - source：用来存放你的文章\n  - themes：主题\n  - ** _config.yml: 博客的配置文件**\n\n  输入命令，看看hexo的效果\n\n  ```\n  hexo g\n  hexo server\n  ```\n\n  打开hexo的服务，在浏览器输入http://localhost:4000就可以看到你生成的博客了。\n\n  按住ctrl+c 可以关闭服务\n\n  ## 1.4 GitHub创建个人仓库\n\n  首先，你先要有一个GitHub账户，去注册一个吧。\n\n  注册完登录后，在GitHub.com中看到一个New repository，新建仓库\n\n  \n\n  创建一个和你用户名相同的仓库，后面加.github.io，只有这样，将来要部署到GitHub page的时候，才会被识别，也就是xxxx.github.io，其中xxx就是你注册GitHub的用户名。我这里是已经建过了。\n\n  \n\n  点击create repository。\n\n  ## 1.5 生成SSH添加到GitHub\n\n  回到你的git bash中，执行命令\n\n  ```cpp\n  git config --global user.name \"yourname\"\n  git config --global user.email \"youremail\"\n  ```\n\n  这里的yourname输入你的GitHub用户名，youremail输入你GitHub的邮箱。这样GitHub才能知道你是不是对应它的账户。\n\n  可以用以下两条，检查一下你有没有输对\n\n  ```cpp\n  ssh-keygen -t rsa -C \"youremail\"\n  ```\n\n  这个时候它会告诉你已经生成了.ssh的文件夹。在你的电脑中找到这个文件夹。\n\n  ssh，简单来讲，就是一个秘钥，其中，id_rsa是你这台电脑的私人秘钥，不能给别人看的，id_rsa.pub是公共秘钥，可以随便给别人看。把这个公钥放在GitHub上，这样当你链接GitHub自己的账户时，它就会根据公钥匹配你的私钥，当能够相互匹配时，才能够顺利的通过git上传你的文件到GitHub上。\n\n  而后在GitHub的setting中，找到SSH keys的设置选项，点击New SSH key\n  把你的id_rsa.pub里面的信息复制进去。\n\n  在gitbash中，查看是否成功，执行命令\n\n  ```cpp\n  ssh -T git@github.com\n  ```\n\n  ## 1.6 将hexo部署到GitHub\n\n  这一步，我们就可以将hexo和GitHub关联起来，也就是将hexo生成的文章部署到GitHub上，打开站点配置文件 `_config.yml`，翻到最后，修改为\n  YourgithubName就是你的GitHub账户\n\n  ```\n  deploy:\n    type: git\n    repo: https://github.com/YourgithubName/YourgithubName.github.io.git\n    branch: master\n  ```\n\n  这个时候需要先安装deploy-git ，也就是部署的命令,这样你才能用命令部署到GitHub。\n\n  ```\n  hexo clean\n  hexo generate\n  hexo deploy\n  ```\n\n  `hexo clean`清除了你之前生成的东西，也可以不加。\n  `hexo generate` 顾名思义，生成静态文章，可以用 `hexo g`缩写\n  `hexo deploy` 部署文章，可以用`hexo d`缩写\n\n  注意deploy时可能要你输入username和password。得到下图就说明部署成功了，过一会儿就可以在`http://yourname.github.io` 这个网站看到你的博客了！！\n\n# 二、Hexo博客配置\n\nhexo的基本配置，更换主题，实现多终端工作，以及在coding page部署实现国内外分流。\n\n## 2.1 hexo 基本配置\n\n|     参数      |                             描述                             |\n| :-----------: | :----------------------------------------------------------: |\n|    `title`    |                           网站标题                           |\n|  `subtitle`   |                          网站副标题                          |\n| `description` |                           网站描述                           |\n|   `author`    |                           您的名字                           |\n|  `language`   |                        网站使用的语言                        |\n|  `timezone`   | 网站时区。Hexo 默认使用您电脑的时区。[时区列表](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)。比如说：`America/New_York`, `Japan`, 和 `UTC` 。 |\n\n|         参数         |                             描述                             |\n| :------------------: | :----------------------------------------------------------: |\n|        `url`         |                             网址                             |\n|        `root`        |                          网站根目录                          |\n|     `permalink`      | 文章的 [永久链接](https://hexo.io/zh-cn/docs/permalinks) 格式 |\n| `permalink_defaults` |                   永久链接中各部分的默认值                   |\n\n在这里，你需要把url改成你的网站域名。\n\npermalink，也就是你生成某个文章时的那个链接格式。\n\n比如我新建一个文章叫temp.md，那么这个时候他自动生成的地址就是http://yoursite.com/2024/07/26/temp。\n\n以下是官方给出的示例，关于链接的变量还有很多，需要的可以去官网上查找 [永久链接 ](https://hexo.io/zh-cn/docs/permalinks)。\n\n```cpp\ntheme: landscape\n\n# Deployment\n## Docs: https://hexo.io/docs/deployment.html\ndeploy:\n  type: git\n  repo: <repository url>\n  branch: [branch]\n```\n\ntheme就是选择什么主题，也就是在theme这个文件夹下，在官网上有很多个主题，默认给你安装的是lanscape这个主题。当你需要更换主题时，在官网上下载，把主题的文件放在theme文件夹下，再修改这个参数就可以了。接下来这个deploy就是网站的部署的，repo就是仓库(Repository)的简写。branch选择仓库的哪个分支。这个在之前进行github page部署的时候已经修改过了，不再赘述。而这个在后面进行双平台部署的时候会再次用到。\n\nFront-matter 是文件最上方以 `---` 分隔的区域，用于指定个别文件的变量，举例来说：\n\n\n\n\n\n## 2.2  更换主题\n\n## 2.3 git分支进行多终端工作\n\n## 2.4 coding page上部署实现国内外分流\n\n\n\n\n\n\n\n# 三、云服务器配置\n\n\n\n\n\n# 四、Hexo常用命令\n\n\n\n\n\n# 五、问题记录\n\n","tags":["pro"],"categories":["project"]},{"title":"深度解析H.266/VVC帧间编码","url":"/2024/07/21/深度解析H-266-帧间编码/","content":"\n\n\n# \n\n帧间预测是利用视频帧与帧之间的相关性，去除视频帧间的时间冗余信息。统计表明，帧间差绝对值超过3的像素平均不到一帧像素的4%，因此，采用高效的帧间编码方式，可以很大程度上提高视频压缩效率。\n\n目前，主流视频编码标准中采用的基于块的帧间编码方式，基本原理是通过运动估计（Motion Estimate）从相邻参考重建帧中寻找和当前块差别最小的参考块，将其重建值作为当前块的预测块。其中参考块到当前块的位移称为运动矢量（Motion Vector），将重建值作为预测值的过程称为运动补偿（Motion Compensation）![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4ba7aa8369fb48b2b22f6172b85a0a68.png)\n\n <!--more--> \n\n\n# VVC帧间预测编码概述\n# MV的预测和获取\nMV预测技术继承和发展了H.265的merge和AMVP技术，拓展了MV预测选择范围，提高MV的表示精度。\n\n（1）**Merge模式**\n\n在MVP候选列表的构造上，保留了空域和时域候选，去除了组合MVP候选，增加了基于历史的MV预测（HMVP）和成对平均MVP候选，并且改变了空域候选的检查顺序。\n\n- 联合帧内帧间预测技术(CIIP)\n- 带有运动矢量差的Merge技术(MMVD)\n- 几何划分帧间预测技术(GPM)\n\n（2）**AMVP模式**\n\n保留原AMVP列表构造方式的同时，引入了HMVP候选的构造。\n在双向AMVP模式的选择上，增加对称运动矢量差分编码AMVD技术。\n引入了CU级的**自适应运动矢量精度（AMVR）**技术，允许多种不同亚像素精度来编码MVD。\n\n（3）**基于子块的MV表示**\n\n新增了基于子块的帧间预测技术，可以一次性表示一个编码块中多个子块不同MV的信息。\n\n基于子块的时域MV预测（SbTMVP），每个子块使用同位图像中对应位置块的运动信息来预测MV。\n仿射运动补偿预测（AMCP）技术，针对缩放、旋转等运动场景。\n\n（4）**解码端MV细化**\n\n为提升双向MV预测的准确性，VVC采用了一种双向MV修正技术，解码端运动会矢量细化（DMVR），在解码端通过基于双边匹配的局部小区域运动搜索，将MV微调后再用于运动补偿。\n\n> 1. Merge模式\n# 一、Merge模式\nMerge模式是HEVC中提出的新技术，直接利用一个或者一组MVP，推断得到当前编码块的MV信息，通常是利用空域和时域相邻块的MV对当前块的MV进行预测直接得到，不存在MVD。因此不需要传输MVD和参考帧索引，是一种高效的MV编码方法。\n\n编解码端会使用相同的方式构建**MV候选列表**，在编码端通过**率失真准则**选出最优的MV索引，只需将该索引传给解码端即可。在VVC中，对于Merge模式下的每个CU的最佳候选索引使用**截断一元二值化**进行编码即可，最佳索引的第一个bin使用**上下文编码**，其他bin使用**旁路编码**。进行运动补偿获取帧间预测块，然后对预测残差进行编码。\n\nHEVC中Merge模式利用时域或空域相邻块构建MV候选列表，且列表中只有5个候选MV。\nVVC在HEVC的基础上进行了扩展，MV候选列表中最多可以有6个候选MV，候选MV有5种类型，顺序如下：\n\n- 基于相邻块的空域MVP\n- 基于同位块的时域MVP\n- 基于历史信息构建的FIFO表的MVP\n- 成对的平均MVP\n- 零MV\n\n## Merge估计区域\nMerge估计区域（MER）允许为同一Merge估计区域中的CU独立推导Merge候选列表。对于当前CU的Merge候选列表推导过程中，不包括与当前CU在同一MER内的候选块，即判断相邻块可用时，仅使用不同MER内的相邻块。在编码器侧选择MER大小，并在序列参数集中以log2_parallel_merge_level_minus2表示。另外，仅当( xCb + cbWidth ) >> Log2ParMrgLevel 大于 xCb >> Log2ParMrgLevel 且 ( yCb + cbHeight ) >> Log2ParMrgLevel 大于 ( yCb >> Log2ParMrgLevel )时更新HMVP候选列表。\n\n## Merge列表构建过程\nMerge list的列表长度为6，首选寻找空域候选项（最多选择4个），然后寻找时域候选项（最多选择1个），然后选择基于历史信息的候选项，最后是平均候选项（最多选择1个），如果Merge list通过以上几个步骤，还未被填满，则使用零向量进行填充。在上面这些步骤当中，如果在中途某个步骤当中merge list被填满则提前终止，不进行后面的步骤。\n\nVVC中的Merge list构建与HEVC中Merge list构建最大的不同在于，HEVC中的Merge list只包括空域候选项和时域候选项\n当前CU的merge list构建完毕后，遍历它的6个候选项进行率失真代价计算，选择率失真代价最小的候选项直接作为当前CU的MV\n注意：对于B slice，由于是双向预测，因此每个候选项包括两个MV（一个前向MV一个后向MV）。在候选列表中，每个候选项包括MV信息和参考帧索引信息。\n\n构建Merge列表的代码及注释如下（基于VTM10.0）：\n\n```cpp\nvoid PU::getInterMergeCandidates( const PredictionUnit &pu, MergeCtx& mrgCtx,\n                                 int mmvdList,\n                                 const int& mrgCandIdx )\n{\n  const unsigned plevel = pu.cs->sps->getLog2ParallelMergeLevelMinus2() + 2;\n  const CodingStructure &cs  = *pu.cs;\n  const Slice &slice         = *pu.cs->slice;\n  const uint32_t maxNumMergeCand = pu.cs->sps->getMaxNumMergeCand();//该变量表示Merge候选列表的最大长度\n  CHECK (maxNumMergeCand > MRG_MAX_NUM_CANDS, \"selected maximum number of merge candidate exceeds global limit\");\n  for (uint32_t ui = 0; ui < maxNumMergeCand; ++ui)\n  {\n    mrgCtx.BcwIdx[ui] = BCW_DEFAULT;\n    mrgCtx.interDirNeighbours[ui] = 0;\n    mrgCtx.mrgTypeNeighbours [ui] = MRG_TYPE_DEFAULT_N;\n    mrgCtx.mvFieldNeighbours[(ui << 1)    ].refIdx = NOT_VALID;\n    mrgCtx.mvFieldNeighbours[(ui << 1) + 1].refIdx = NOT_VALID;\n    mrgCtx.useAltHpelIf[ui] = false;\n  }\n \n  mrgCtx.numValidMergeCand = maxNumMergeCand;\n  // compute the location of the current PU 计算当前PU的位置\n \n  int cnt = 0;\n \n  const Position posLT = pu.Y().topLeft();//当前PU左上方的位置\n  const Position posRT = pu.Y().topRight();//当前PU右上方的位置\n  const Position posLB = pu.Y().bottomLeft();//当前PU左下方的位置\n  MotionInfo miAbove, miLeft, miAboveLeft, miAboveRight, miBelowLeft; //记录当前PU5个相邻块的运动信息\n \n  // above\n  const PredictionUnit *puAbove = cs.getPURestricted(posRT.offset(0, -1), pu, pu.chType);\n  // ===========================空域MV候选列表的构建=======================\n  bool isAvailableB1 = puAbove && isDiffMER(pu.lumaPos(), posRT.offset(0, -1), plevel) && pu.cu != puAbove->cu && CU::isInter(*puAbove->cu);\n  // 右上方B1块可用\n  if (isAvailableB1)\n  {\n    miAbove = puAbove->getMotionInfo(posRT.offset(0, -1)); //获取B1块的运动信息\n \n    // get Inter Dir\n    mrgCtx.interDirNeighbours[cnt] = miAbove.interDir; //该变量表示merge list中已候选项的数目\n    mrgCtx.useAltHpelIf[cnt] = miAbove.useAltHpelIf;\n    // get Mv from Above 从上方块获得运动矢量\n    // puAbove->cu->BcwIdx表示当前PU所属的CU维护的HMVP表中候选数目\n    mrgCtx.BcwIdx[cnt] = (mrgCtx.interDirNeighbours[cnt] == 3) ? puAbove->cu->BcwIdx : BCW_DEFAULT;\n    mrgCtx.mvFieldNeighbours[cnt << 1].setMvField(miAbove.mv[0], miAbove.refIdx[0]); //使用前向参考帧的MV\n \n    if (slice.isInterB())\n    { //如果是B帧，则还需要获得相邻块后向参考帧的MV\n      mrgCtx.mvFieldNeighbours[(cnt << 1) + 1].setMvField(miAbove.mv[1], miAbove.refIdx[1]);\n    }\n    if (mrgCandIdx == cnt)\n    {\n      return;\n    }\n \n    cnt++;\n  }\n \n  // early termination 如果当前merge list中候选的数目已经达到了最大值，则停止merge list列表的构建\n  if (cnt == maxNumMergeCand)\n  {\n    return;\n  }\n \n  //left 检查左侧块A1运动信息是否可用\n  const PredictionUnit* puLeft = cs.getPURestricted(posLB.offset(-1, 0), pu, pu.chType);\n \n  const bool isAvailableA1 = puLeft && isDiffMER(pu.lumaPos(), posLB.offset(-1, 0), plevel) && pu.cu != puLeft->cu && CU::isInter(*puLeft->cu);\n \n  if (isAvailableA1)\n  {\n    miLeft = puLeft->getMotionInfo(posLB.offset(-1, 0));\n \n    if (!isAvailableB1 || (miAbove != miLeft))// 冗余性检查\n    {\n      // get Inter Dir\n      mrgCtx.interDirNeighbours[cnt] = miLeft.interDir;\n      mrgCtx.useAltHpelIf[cnt] = miLeft.useAltHpelIf;\n      mrgCtx.BcwIdx[cnt] = (mrgCtx.interDirNeighbours[cnt] == 3) ? puLeft->cu->BcwIdx : BCW_DEFAULT;\n      // get Mv from Left\n      mrgCtx.mvFieldNeighbours[cnt << 1].setMvField(miLeft.mv[0], miLeft.refIdx[0]);\n \n      if (slice.isInterB())\n      {\n        mrgCtx.mvFieldNeighbours[(cnt << 1) + 1].setMvField(miLeft.mv[1], miLeft.refIdx[1]);\n      }\n      if (mrgCandIdx == cnt)\n      {\n        return;\n      }\n \n      cnt++;\n    }\n  }\n \n  // early termination\n  if( cnt == maxNumMergeCand )\n  {\n    return;\n  }\n \n  // above right 检查右上相邻块B0运动信息是否可用\n  const PredictionUnit *puAboveRight = cs.getPURestricted( posRT.offset( 1, -1 ), pu, pu.chType );\n \n  bool isAvailableB0 = puAboveRight && isDiffMER( pu.lumaPos(), posRT.offset(1, -1), plevel) && CU::isInter( *puAboveRight->cu );\n \n  if( isAvailableB0 )\n  {\n    miAboveRight = puAboveRight->getMotionInfo( posRT.offset( 1, -1 ) );\n \n    if( !isAvailableB1 || ( miAbove != miAboveRight ) )// 冗余性检查\n    {\n      // get Inter Dir\n      mrgCtx.interDirNeighbours[cnt] = miAboveRight.interDir;\n      mrgCtx.useAltHpelIf[cnt] = miAboveRight.useAltHpelIf;\n      // get Mv from Above-right\n      mrgCtx.BcwIdx[cnt] = (mrgCtx.interDirNeighbours[cnt] == 3) ? puAboveRight->cu->BcwIdx : BCW_DEFAULT;\n      mrgCtx.mvFieldNeighbours[cnt << 1].setMvField( miAboveRight.mv[0], miAboveRight.refIdx[0] );\n \n      if( slice.isInterB() )\n      {\n        mrgCtx.mvFieldNeighbours[( cnt << 1 ) + 1].setMvField( miAboveRight.mv[1], miAboveRight.refIdx[1] );\n      }\n \n      if (mrgCandIdx == cnt)\n      {\n        return;\n      }\n \n      cnt++;\n    }\n  }\n  // early termination\n  if( cnt == maxNumMergeCand )\n  {\n    return;\n  }\n \n  //left bottom 检查左下相邻块A0运动信息是否可用\n  const PredictionUnit *puLeftBottom = cs.getPURestricted( posLB.offset( -1, 1 ), pu, pu.chType );\n \n  bool isAvailableA0 = puLeftBottom && isDiffMER( pu.lumaPos(), posLB.offset(-1, 1), plevel) && CU::isInter( *puLeftBottom->cu );\n \n  if( isAvailableA0 )\n  {\n    miBelowLeft = puLeftBottom->getMotionInfo( posLB.offset( -1, 1 ) );\n    \n    if( !isAvailableA1 || ( miBelowLeft != miLeft ) )// 冗余性检查\n    {\n      // get Inter Dir\n      mrgCtx.interDirNeighbours[cnt] = miBelowLeft.interDir;\n      mrgCtx.useAltHpelIf[cnt] = miBelowLeft.useAltHpelIf;\n      mrgCtx.BcwIdx[cnt] = (mrgCtx.interDirNeighbours[cnt] == 3) ? puLeftBottom->cu->BcwIdx : BCW_DEFAULT;\n      // get Mv from Bottom-Left\n      mrgCtx.mvFieldNeighbours[cnt << 1].setMvField( miBelowLeft.mv[0], miBelowLeft.refIdx[0] );\n \n      if( slice.isInterB() )\n      {\n        mrgCtx.mvFieldNeighbours[( cnt << 1 ) + 1].setMvField( miBelowLeft.mv[1], miBelowLeft.refIdx[1] );\n      }\n \n      if (mrgCandIdx == cnt)\n      {\n        return;\n      }\n \n      cnt++;\n    }\n  }\n  // early termination\n  if( cnt == maxNumMergeCand )\n  {\n    return;\n  }\n \n  // above left 如果前四个相邻块由一个不可用， 则继续检查左上角的B2块是否可用\n  if ( cnt < 4 )\n  {\n    const PredictionUnit *puAboveLeft = cs.getPURestricted( posLT.offset( -1, -1 ), pu, pu.chType );\n \n    bool isAvailableB2 = puAboveLeft && isDiffMER( pu.lumaPos(), posLT.offset(-1, -1), plevel ) && CU::isInter( *puAboveLeft->cu );\n \n    if( isAvailableB2 )\n    {\n      miAboveLeft = puAboveLeft->getMotionInfo( posLT.offset( -1, -1 ) );\n      // 冗余性检查\n      if( ( !isAvailableA1 || ( miLeft != miAboveLeft ) ) && ( !isAvailableB1 || ( miAbove != miAboveLeft ) ) )\n      {\n        // get Inter Dir\n        mrgCtx.interDirNeighbours[cnt] = miAboveLeft.interDir;\n        mrgCtx.useAltHpelIf[cnt] = miAboveLeft.useAltHpelIf;\n        mrgCtx.BcwIdx[cnt] = (mrgCtx.interDirNeighbours[cnt] == 3) ? puAboveLeft->cu->BcwIdx : BCW_DEFAULT;\n        // get Mv from Above-Left\n        mrgCtx.mvFieldNeighbours[cnt << 1].setMvField( miAboveLeft.mv[0], miAboveLeft.refIdx[0] );\n \n        if( slice.isInterB() )\n        {\n          mrgCtx.mvFieldNeighbours[( cnt << 1 ) + 1].setMvField( miAboveLeft.mv[1], miAboveLeft.refIdx[1] );\n        }\n \n        if (mrgCandIdx == cnt)\n        {\n          return;\n        }\n \n        cnt++;\n      }\n    }\n  }\n  // early termination\n  if (cnt == maxNumMergeCand)\n  {\n    return;\n  }\n \n  // =======================时域MVP候选列表的构建==============================\n  if (slice.getPicHeader()->getEnableTMVPFlag() && (pu.lumaSize().width + pu.lumaSize().height > 12))\n  {\n    //>> MTK colocated-RightBottom\n    // offset the pos to be sure to \"point\" to the same position the uiAbsPartIdx would've pointed to\n    // 偏移pos，确保“指向”uiAbsPartIdx将指向的相同位置\n    Position posRB = pu.Y().bottomRight().offset( -3, -3 );\n    const PreCalcValues& pcv = *cs.pcv;\n \n    Position posC0;//C0位当前PU的右下方再移位(1,1)\n    Position posC1 = pu.Y().center(); //C1为当前PU的中心位置\n    bool C0Avail = false;\n    bool boundaryCond = ((posRB.x + pcv.minCUWidth) < pcv.lumaWidth) && ((posRB.y + pcv.minCUHeight) < pcv.lumaHeight);\n    const SubPic& curSubPic = pu.cs->slice->getPPS()->getSubPicFromPos(pu.lumaPos()); //获得当前PU所在的子图\n    if (curSubPic.getTreatedAsPicFlag())\n    {\n      // 在不包括环路内滤波操作的解码处理中，是否将子图视为图\n      boundaryCond = ((posRB.x + pcv.minCUWidth) <= curSubPic.getSubPicRight() &&\n                      (posRB.y + pcv.minCUHeight) <= curSubPic.getSubPicBottom()); \n    }\n    if (boundaryCond)\n    {\n      int posYInCtu = posRB.y & pcv.maxCUHeightMask;\n      if (posYInCtu + 4 < pcv.maxCUHeight)\n      {\n        posC0 = posRB.offset(4, 4);\n        C0Avail = true; //C0位置处的像素可用\n      }\n    }\n    Mv        cColMv;\n    int       iRefIdx     = 0;\n    int       dir         = 0;\n    unsigned  uiArrayAddr = cnt;\n    //检查是否存在同位MV，若存在则获取相应的MV到cColMv\n    bool      bExistMV    = ( C0Avail && getColocatedMVP(pu, REF_PIC_LIST_0, posC0, cColMv, iRefIdx, false ) )\n                              || getColocatedMVP( pu, REF_PIC_LIST_0, posC1, cColMv, iRefIdx, false ); \n    if (bExistMV)\n    {\n      dir     |= 1;\n      mrgCtx.mvFieldNeighbours[2 * uiArrayAddr].setMvField(cColMv, iRefIdx);\n    }\n \n    if (slice.isInterB())\n    { //对于B帧，相应的获取两个MV\n      bExistMV = ( C0Avail && getColocatedMVP(pu, REF_PIC_LIST_1, posC0, cColMv, iRefIdx, false ) )\n                   || getColocatedMVP( pu, REF_PIC_LIST_1, posC1, cColMv, iRefIdx, false );\n      if (bExistMV)\n      {\n        dir     |= 2;\n        mrgCtx.mvFieldNeighbours[2 * uiArrayAddr + 1].setMvField(cColMv, iRefIdx);\n      }\n    }\n \n    if( dir != 0 )\n    {\n      bool addTMvp = true;\n      if( addTMvp )\n      {\n        mrgCtx.interDirNeighbours[uiArrayAddr] = dir;\n        mrgCtx.BcwIdx[uiArrayAddr] = BCW_DEFAULT;\n        mrgCtx.useAltHpelIf[uiArrayAddr] = false;\n        if (mrgCandIdx == cnt)\n        {\n          return;\n        }\n        cnt++;\n      }\n    }\n  }\n \n  // early termination 提前终止\n  if (cnt == maxNumMergeCand)\n  {\n    return;\n  }\n \n  //=================================基于历史信息构建MV列表===========================\n  int maxNumMergeCandMin1 = maxNumMergeCand - 1;\n  if (cnt != maxNumMergeCandMin1) //检查Merge列表是否到达最大数目减1，如果到达则不需要进行HMV候选\n  {\n    bool isGt4x4 = true;\n    bool bFound  = addMergeHMVPCand(cs, mrgCtx, mrgCandIdx, maxNumMergeCandMin1, cnt, isAvailableA1, miLeft,\n                                   isAvailableB1, miAbove, CU::isIBC(*pu.cu), isGt4x4);\n \n    if (bFound)\n    {\n      return;\n    }\n  }\n  // ================================成对平均候选MV==================================\n  // pairwise-average candidates\n  {\n    if (cnt > 1 && cnt < maxNumMergeCand)\n    {\n      mrgCtx.mvFieldNeighbours[cnt * 2].setMvField( Mv( 0, 0 ), NOT_VALID );\n      mrgCtx.mvFieldNeighbours[cnt * 2 + 1].setMvField( Mv( 0, 0 ), NOT_VALID );\n      // calculate average MV for L0 and L1 seperately 分别计算L0和L1的平均MV\n      unsigned char interDir = 0;\n      // 设置滤波器指数\n      mrgCtx.useAltHpelIf[cnt] = (mrgCtx.useAltHpelIf[0] == mrgCtx.useAltHpelIf[1]) ? mrgCtx.useAltHpelIf[0] : false;\n      for( int refListId = 0; refListId < (slice.isInterB() ? 2 : 1); refListId++ )\n      {\n        // 使用列表中最前面的两个MV\n        const short refIdxI = mrgCtx.mvFieldNeighbours[0 * 2 + refListId].refIdx;\n        const short refIdxJ = mrgCtx.mvFieldNeighbours[1 * 2 + refListId].refIdx;\n \n        // both MVs are invalid, skip 两个MVs都无效，跳过\n        if( (refIdxI == NOT_VALID) && (refIdxJ == NOT_VALID) )\n        {\n          continue;\n        }\n \n        interDir += 1 << refListId;\n        // both MVs are valid, average these two MVs 两个MVs都有效，平均这两个MVs\n        if( (refIdxI != NOT_VALID) && (refIdxJ != NOT_VALID) )\n        {\n          const Mv& MvI = mrgCtx.mvFieldNeighbours[0 * 2 + refListId].mv;\n          const Mv& MvJ = mrgCtx.mvFieldNeighbours[1 * 2 + refListId].mv;\n \n          // average two MVs\n          Mv avgMv = MvI;\n          avgMv += MvJ;\n          roundAffineMv(avgMv.hor, avgMv.ver, 1);\n          mrgCtx.mvFieldNeighbours[cnt * 2 + refListId].setMvField( avgMv, refIdxI );\n        }\n        // only one MV is valid, take the only one MV 只有一个MV有效，只取一个MV\n        else if( refIdxI != NOT_VALID )\n        {\n          Mv singleMv = mrgCtx.mvFieldNeighbours[0 * 2 + refListId].mv;\n          mrgCtx.mvFieldNeighbours[cnt * 2 + refListId].setMvField( singleMv, refIdxI );\n        }\n        else if( refIdxJ != NOT_VALID )\n        {\n          Mv singleMv = mrgCtx.mvFieldNeighbours[1 * 2 + refListId].mv;\n          mrgCtx.mvFieldNeighbours[cnt * 2 + refListId].setMvField( singleMv, refIdxJ );\n        }\n      }\n \n      mrgCtx.interDirNeighbours[cnt] = interDir;\n      if( interDir > 0 )\n      {\n        cnt++;\n      }\n    }\n \n    // early termination 提前终止\n    if( cnt == maxNumMergeCand )\n    {\n      return;\n    }\n  }\n \n  uint32_t uiArrayAddr = cnt;\n \n  int iNumRefIdx = slice.isInterB() ? std::min(slice.getNumRefIdx(REF_PIC_LIST_0), slice.getNumRefIdx(REF_PIC_LIST_1)) : slice.getNumRefIdx(REF_PIC_LIST_0);\n \n  int r = 0;\n  int refcnt = 0;\n  // =================================零MV============================\n  while (uiArrayAddr < maxNumMergeCand)\n  {\n    mrgCtx.interDirNeighbours [uiArrayAddr     ] = 1;\n    mrgCtx.BcwIdx             [uiArrayAddr     ] = BCW_DEFAULT;\n    mrgCtx.mvFieldNeighbours  [uiArrayAddr << 1].setMvField(Mv(0, 0), r);\n    mrgCtx.useAltHpelIf[uiArrayAddr] = false;\n \n    if (slice.isInterB())\n    {\n      mrgCtx.interDirNeighbours [ uiArrayAddr          ] = 3;\n      mrgCtx.mvFieldNeighbours  [(uiArrayAddr << 1) + 1].setMvField(Mv(0, 0), r);\n    }\n \n    if ( mrgCtx.interDirNeighbours[uiArrayAddr] == 1 && pu.cs->slice->getRefPic(REF_PIC_LIST_0,            mrgCtx.mvFieldNeighbours[uiArrayAddr << 1].refIdx)->getPOC() == pu.cs->slice->getPOC())\n    {\n      mrgCtx.mrgTypeNeighbours[uiArrayAddr] = MRG_TYPE_IBC;\n    }\n \n    uiArrayAddr++;\n \n    if (refcnt == iNumRefIdx - 1)\n    {\n      r = 0;\n    }\n    else\n    {\n      ++r;\n      ++refcnt;\n    }\n  }\n  mrgCtx.numValidMergeCand = uiArrayAddr;\n}\n```\n从HMVP列表获得Merge候选列表的代码如下：\n\n```cpp\nbool PU::addMergeHMVPCand(const CodingStructure &cs, MergeCtx &mrgCtx, const int &mrgCandIdx,\n                          const uint32_t maxNumMergeCandMin1, int &cnt, const bool isAvailableA1,\n                          const MotionInfo miLeft, const bool isAvailableB1, const MotionInfo miAbove,\n                          const bool ibcFlag, const bool isGt4x4)\n{\n  const Slice& slice = *cs.slice;\n  MotionInfo miNeighbor;\n \n  auto &lut = ibcFlag ? cs.motionLut.lutIbc : cs.motionLut.lut; //HMVP列表\n  int num_avai_candInLUT = (int)lut.size();//HMVP列表的长度\n \n  for (int mrgIdx = 1; mrgIdx <= num_avai_candInLUT; mrgIdx++) //遍历HMVP列表\n  {\n    miNeighbor = lut[num_avai_candInLUT - mrgIdx]; //先取HMVP列表中的后面几项\n \n    // 冗余性检查\n    if ( mrgIdx > 2 || ((mrgIdx > 1 || !isGt4x4) && ibcFlag)\n      || ((!isAvailableA1 || (miLeft != miNeighbor)) && (!isAvailableB1 || (miAbove != miNeighbor))) )\n    {\n      mrgCtx.interDirNeighbours[cnt] = miNeighbor.interDir;\n      mrgCtx.useAltHpelIf      [cnt] = !ibcFlag && miNeighbor.useAltHpelIf;\n      mrgCtx.BcwIdx            [cnt] = (miNeighbor.interDir == 3) ? miNeighbor.BcwIdx : BCW_DEFAULT;\n \n      mrgCtx.mvFieldNeighbours[cnt << 1].setMvField(miNeighbor.mv[0], miNeighbor.refIdx[0]);\n      if (slice.isInterB())\n      {\n        mrgCtx.mvFieldNeighbours[(cnt << 1) + 1].setMvField(miNeighbor.mv[1], miNeighbor.refIdx[1]);\n      }\n \n      if (mrgCandIdx == cnt)\n      {\n        return true;\n      }\n      cnt ++;\n \n      if (cnt  == maxNumMergeCandMin1) //如果Merge列表长度到达maxNumMergeCandMin1，则停止加入列表\n      {\n        break;\n      }\n    }\n  }\n \n  if (cnt < maxNumMergeCandMin1)\n  {\n    mrgCtx.useAltHpelIf[cnt] = false;\n  }\n \n  return false;\n}\n```\n\n\n\n## 1.1 常规Merge模式\n直接将MVP运动矢量信息（参考图像索引、运动矢量）作为当前CU运动矢量信息的帧间模式编码。需要建立一个MVP候选列表（MergeMVP），选择一个MVP作为当前CU的MV，就可以得到当前CU的像素预测值，进一步编码预测残差。\n\n**MergeMVP列表**构造较为复杂，是Merge模式最关键的环节，候选最多为6个。依次包含\nVVC在HEVC的基础上，扩展了Merge模式构造Merge List的方法，Merge List最多可以包含6个候选MV，构造方法如下：\n\n- 基于空间相邻块的空域MVP（最多提供4个候选MV）\n- 基于同位块的时域MVP（最多提供1个候选MV）\n- 基于历史信息的MVP（不限个数，直到填充到Merge List包含5个候选MV）\n- 成对平均MVP（由Merge List中前两个候选MV平均得到）\n- 零MV\n\n### 1.1.1 空域候选MVP：\n空域候选列表建立方式和HEVC一样。如下图所示，A1为当前CU左下处的相邻CU,B1为当前CU右上处的相邻CU，B2为当前CU的左上相邻CU，A0和B0分别为距离A1和B1处最近的CU。VVC中空域最多提供4个候选MV，即最多使用这5个候选块中的4个候选块的运动信息，候选列表按照B1->A1->B0->A0->(B2)的顺序建立，其中B2是替补，只有前4个有一个或多个不存在时（例如不再同一个slice或tile或使用帧内编码）才将B2加入候选列表。\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/edf3ce1d6872450ebbb28a3dcaff83f5.png)\n\n当候选列表加入B1后，后面新加入候选项时要进行冗余性检查以免新加入的候选项的运动信息和已有项的相同。为了减少计算复杂度，冗余性检查时不会和已有的每一项进行比较，只比下图中较箭头连接的项。\n![冗余检查](https://i-blog.csdnimg.cn/direct/34e8c460656740c291919673327a7ebe.png)\n这里的图和代码中并不完全一致，实际上，因为先进入列表的是B1，所以对于B1项，不需要进行冗余性检查，对于A1项，检查是否和B1冗余。其余项的检查和图中一致，注意对于B2项，要同时检查和B1、A1项是否冗余。\n检查冗余性时，所检查的是运动信息，包括MV、参考帧索引等运动信息，如下代码所示：在代码重载了==和!=运算符，通过调用!=，进行冗余性检查\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/d0d129df6c134d1d91dd2172f74e1f94.png)\n\n\n\n```cpp\nstruct MotionInfo\n{\n  bool     isInter;\n  bool     isIBCmot;\n  char     interDir;\n  bool     useAltHpelIf;\n  uint16_t   sliceIdx;\n  Mv      mv     [ NUM_REF_PIC_LIST_01 ];\n  int16_t   refIdx [ NUM_REF_PIC_LIST_01 ];\n  uint8_t         BcwIdx;\n  Mv      bv;\n  MotionInfo() : isInter(false), isIBCmot(false), interDir(0), useAltHpelIf(false), sliceIdx(0), refIdx{ NOT_VALID, NOT_VALID },   BcwIdx(0) { }\n \n  MotionInfo(int i) : isInter(i != 0), isIBCmot(false), interDir(0), useAltHpelIf(false), sliceIdx(0), refIdx{ 0,         0 }, BcwIdx(0) { CHECKD(i != 0, \"The argument for this constructor has to be '0'\"); }\n \n  bool operator==( const MotionInfo& mi ) const\n  {\n    if( isInter != mi.isInter  ) return false;\n    if (isIBCmot != mi.isIBCmot) return false;\n    if( isInter )\n    {\n      if( sliceIdx != mi.sliceIdx ) return false;\n      if( interDir != mi.interDir ) return false;\n \n      if( interDir != 2 )\n      {\n        if( refIdx[0] != mi.refIdx[0] ) return false;\n        if( mv[0]     != mi.mv[0]     ) return false;\n      }\n \n      if( interDir != 1 )\n      {\n        if( refIdx[1] != mi.refIdx[1] ) return false;\n        if( mv[1]     != mi.mv[1]     ) return false;\n      }\n    }\n \n    return true;\n  }\n \n  bool operator!=( const MotionInfo& mi ) const\n  {\n    return !( *this == mi );\n  }\n};\n```\n\n\n### 1.1.2 时域候选MVP：\n利用当前CU在时域邻近已编码图像中对应位置CU来确定，叫做同位图像（ColPic），但是需要按照位置关系进行比例伸缩调整。参考时域距离（图片顺序技术POC）。最多提供一个时域MVP。\n\n时域最多提供1个候选MV，时域候选列表的构建方式和HEVC一样，与空域的构建方式不同，时域候选列表不能直接使用候选块的运动信息，需要根据位置关系进行相应比例地伸缩。如下图所示\n![时域列表](https://i-blog.csdnimg.cn/direct/c410527e554148edb85a6382d3d70acb.png)\n其中tb表示当前图像和参考图像之间的距离（用POC度量），td是同位图像和其参考图像之间的距离。时域最多提供一个MV，计算方法如下所示：\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/70b6df30258a409eba97ae44e9146026.png)\n### 1.1.3 基于历史的候选MVP\n将先前已编码块的运动信息存储在一个最大长度为5的HMVP列表中，随着编码过程不断更新，按照先进先出的原则保持列表控制冗余，每个CTU行重新置0。如果MergeMVP列表还有空域位置，就按照HMVP列表顺序添加不同的选项。在空域候选和时域候选推导完成之后，将HMVP的Merge候选项加入Merge候选列表。\n\nHMVP候选项来自于一个先进先出的表，表的长度为6，这个表通过已经编码块的运动信息构建，每到新的一行CTU时，这个表就要重置，即清空操作。每遇到一个帧间编码的CU（非子块）时，它相关的运动信息就会加到这个表的最后一项成为一个新的HMVP候选项。每当插入一个新的候选项时，首先要进行冗余性检查即检查待插入的项的运动信息和表中已有项的运动信息是否相同，如果不相同，则按照先进先出的规则进行插入操作；如果相同，则将相同的HMVP从维护的FIFO（先进先出）表中移除，其后所有的项都向前移动一位，将待插入的候选项插入到HMVP的表的末端。\n\n在使用HMVP候选项构建Merge候选列表时，按顺序检查HMVP列表中最新的HMVP候选（从后向前检查），在和Merge列表中现存的候选检查完冗余之后将不重复的HMVP候选添加到Merge列表中去。直到候选列表的长度达到5个。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4f4ebb77860d4f16bcf55a10dcfa1cc2.png)\n为了减少冗余性检查操作，进行了以下的简化操作：\n\n用于构建Merge list的HMVP候选项数量设为 （N<=4)?M:(8-N)，其中N表示Merge list中已有项的数目，M表示HMVP表中候选项数目。一旦Merge list中候选项的数目达到了最大允许候选项数目减一（即6-1=5），则停止从HMVP生成merge候选项的过程\nHMVP列表由cs控制\n\n```cpp\nstruct LutMotionCand\n{\n  static_vector<MotionInfo, MAX_NUM_HMVP_CANDS> lut;\n  static_vector<MotionInfo, MAX_NUM_HMVP_CANDS> lutIbc;\n};\n```\n\n```cpp\nvoid CodingStructure::addMiToLut(static_vector<MotionInfo, MAX_NUM_HMVP_CANDS> &lut, const MotionInfo &mi)\n{\n  size_t currCnt = lut.size();\n \n  bool pruned      = false;\n  int  sameCandIdx = 0;\n \n  for (int idx = 0; idx < currCnt; idx++) //判断HMVP列表中是否存在当前模式信息\n  {\n    if (lut[idx] == mi)\n    {\n      sameCandIdx = idx;\n      pruned      = true;// 如果存在，则将其从列表删除\n      break;\n    }\n  }\n  // 如果当前模式信息已经在模式列表中，则删除\n  // 或者当前模式列表已满，则删除最前面的模式\n  if (pruned || currCnt == lut.capacity()) \n  {\n    lut.erase(lut.begin() + sameCandIdx);\n  }\n \n  lut.push_back(mi); //将模式信息加入到HMVP列表中\n}\n```\n\n ### 1.1.4 成对平均候选MVP\n 如果还有位置，就使用平均候选AvgCnd来补充列表\n使用Merge候选列表中前两个候选项对来生成**成对平均候选mvp**。Merge列表中的第一项和第二项分别定义为p0Cand和p1Cand。对于每个参考帧列表，分别**根据p0Cand和p1Cand的MV是否可用**来计算平均MV。即：\n\n-- 如果两个MV在一个列表中可用，则即使这两个MV指向不同的参考帧，也对它们进行平均，并且其参考帧被设置为p0Cand对应的参考帧；\n-- 如果只有一个MV可用，直接使用那一个；\n-- 如果没有可用的运动矢量，则保持此列表无效。\n-- 如果p0Cand和p1Cand的半像素插值滤波器指数不同，则将其滤波器指数设置为0。\n\n\n### 1.1.5 零值MVP：\n还剩下就将单向、双向、值为（0，0）的MV补充道MergeMVP列表的末端\n如果计算完平均候选项后Merge还未填满，则用0MV填充候选列表，直到候选列表达到最大长度。\n## 1.2 SKIP模式\nSkip由cu_skip_flag标记,是一种特殊的Merge模式。直接用MVP信息作为当前CU的运动矢量，除了不编码MVD信息，也不编码预测残差信息。只需要MVP信息索引，编码比特数很少。相应的在解码器只需要解析出该索引下的运动信息，然后通过运动补偿得到的预测像素值直接作为重建像素值。Skip模式可以大大减少传输比特数。Skip模式也可以是MMVD\\GPM\\SbTMVP和仿射Merge等的拓展模式。\n![Skip模式](https://i-blog.csdnimg.cn/direct/bb22aac777a848a8b848be9b3f54b51a.png)\n\n## 1.3 带有运动矢量差的Merge模式（MMVD）\n因为视频相邻区域CU往往有不同的运动特性，常规merge降低了MV编码比特数，但也因为不准确的MV产生大的预测误差。AMVP技术编码运动矢量的预测残差MVD，与MVP一起表示运动矢量。\n\n但是AMVP模式下的MVD通常需要较多的比特表达，所以VVC引入了一种带有运动矢量差的merge技术MMVD，设定了包含多个固定值的M_MVd集合，选取集合中的一个值作为当前CU的MVD。MVD和MVP都是通过索引获得，MVP必须为mergeMVD列表前2项候选项。M_MVd对应4种方向上8种偏移步长，共2*8*4=64个新的运动矢量候选项。具体单项预测和双向预测，需要根据时间信息进行缩放。\n\n为了进一步提高Merge/Skip模式下预测MV的准确性，VVC在常规Merge模式基础上，增加了“运动矢量差的”Merge模式。该模式是将常规Merge模式构建得到的Merge列表中的前两个候选MV作为初始MV，在上下左右四个方向上，进行8种步长的搜索，即在初始MV基础上加上一定的偏移MVD得到2x4x8=64个MV，并从中选出率失真代价最小的MV作为最终的细化MV。在编码端，将初始MV在Merge List中的索引、搜索方向索引和搜素步长索引传给解码端。\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/64c853afcb814351a392b97f0b877c75.png)\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/d1946ccdff4c4eb5a4b27a1b27608b22.png)\n具体细节和代码参考：[带有运动矢量差的Merge技术(Merge mode with MVD)](https://blog.csdn.net/BigDream123/article/details/116976112)\n\n## 1.4 联合帧内帧间预测模式（CIIP）\n利用帧内预测值和帧间预测值的加权平均得到当前CU预测值的技术。限定帧内预测只采用planar模式，帧间预测只采用常规merge模式，CU的尺寸和形状有限定。VVC对于Merge模式编码的CU，加入了帧内和帧间联合预测技术，即使用常规Merge模式通过运动补偿得到帧间预测信号Pinter ； 通过planar模式得到帧内预测信号Pintra 。 然后，使用加权平均对帧内和帧间预测信号进行组合，计算公式如下所示：\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/d076e82066cd446d9f6298be0e8f5885.png)\n其中权重取决于上相邻块和左相邻块的编码模式。\n\nCIIP使用条件：\nMerge模式编码的CU\nCU包含至少64个亮度像素（即CU宽度乘以CU高度等于或大于64），并且CU宽度和CU高度均小于128， \n具体细节和代码参考：[帧间和帧内联合预测(Combined inter and intra prediction, CIIP)](https://blog.csdn.net/BigDream123/article/details/117171786)\n##  1.5 几何划分预测模式（GPM）\nVVC中，CTU可以经过二叉、三叉、四叉树划分，但是实际视频内容和多样，当物体运动具有非水平或垂直边缘的时候，不能有效匹配，所以引入几何帧间预测模式，允许使用非水平或垂直直线对矩形CU进行划分，每个子区域可以使用不同的运动信息进行运动补偿。从而提升预测准确度。为merge拓展模式。针对运动物体的边缘部分，VVC引入了一种几何划分模式，该模式可以将图像中运动物体的边缘部分，采用更灵活的表示方法。具体地，对于图像中运动物体的边缘CU，可以将其划分为两个非矩形的子CU分别进行单向预测，并进行加权融合，得到整个CU的预测值。\n\n使用GPM模式时，通过几何定位的直线将CU划分为两部分（下图所示）。\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c4c1f8c3fbc8447685d342aedbeed944.png)CU划分后的子分区中包含单独的运动信息，每个子分区仅允许单向预测，如下图所示，当前CU的右侧部分来自参考帧P0的MV0预测，左侧部分来自参考帧P1的MV1预测。最终通过使用整数融合矩阵W0和W1进行边缘融合生成最终的GPM预测PG。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/5a6e64ba30ea403f92ace3359998c570.png)\n为了简化运动信息编码，GPM两个分区的运动信息使用Merge模式编码，GPM模式的候选列表是由常规Merge模式推导而来的。 \n具体细节和代码参考：[带有运动矢量差的Merge技术(Merge mode with MVD)](https://blog.csdn.net/BigDream123/article/details/116976112)\n\n\n**原理**\n为了区分不同的物体，可能在物体边缘产生大量小块，消耗过多头信息，且划分边缘与实际边缘不符合，无法有效表示非垂直边缘。\n\nGPM使用直线将矩形CU划分成2个不规则子区域，拥有自己的运动矢量信息，并进行相应的单向运动补偿。划分线可以用角度和偏移量表示，使用法线和点到直线的距离来表示。VVC中角度和偏移量只允许选择部分预定义的离散数值。各区域分别利用不同运动信息获得补偿，并对划分线附近区域以软混合的方式进行加权融合，以模拟自然场景中柔和的边缘过度。\n\n**几何划分**：共支持64种划分方式。\n子区域运动矢量：两个子区域都只使用单项预测，并以merge模式编码，运动矢量由GPM模式专用的单向MVP候选列表、列表索引获得。\n\n**运动补偿加权融合**：为了避免划分线附近像素值的突变，距离话分享较近像素的权重渐变，融合了两个方向的预测值，模拟柔和过渡。\n\n**运动信息存储**：1、当子块中心位置到划分线距离大于等于2时，存储运动矢量为中心所在子区域的运动矢量2、当划分线小于等于2的时候，如果两个子区域运动矢量所在参考列表不同，则作为双向预测分别存储两个运动矢量信息，如果两个子区域运动矢量所在参考列表相同，则取第二个预测分区的运动矢量作为单项预测存储。\n\n> 2. AMVP\n\n# 二、高级运动矢量预测技术（AMVP）\nAMVP模式是H.265/HEVC中提出的新的MV预测技术，H.266/VVC仍采用了该技术，并在HEVC的基础上进行了改进。AMVP通过高效表达运动矢量插值MVDF进行运动信息编码。主要是利用空域和时域的运动矢量的相关性，为当前PU建立了候选预测MV列表，编码端从其中选出最优的预测MVP，并对MVP进行**差分编码**（即通过运动搜索获得真正的MV，将运动矢量差进行编码（MV-MVP））；解码端通过建立相同的列表，仅需要**预测MVP在列表中的索引**和**运动向量残差MVD**即可计算出当前PU的MV。\n\nMerge与AMVP模式的区别：\n\n- **MVP和MVD差异**：\nMerge模式是直接将通过空域和时域MV的相关性获得的预测MVP作为最终的MV，而不存在MVD；\nAMVP模式是以相关性得到预测MVP作为搜索起点，通过**运动搜索**获得更准确的MVP，然后再将预测的MVP和搜索得到的MV之间的差值MVD进行编码\n- **编码传输内容差异**\nMerge模式仅需要传最佳预测MV在候选列表中的索引；\nAMVP模式除了需要传最佳MVP在候选列表的索引，还需要对运动矢量差MVD进行编码\n- **Merge模式和AMVP模式的候选列表长度不同**\n(Merge模式的候选列表长度为6，AMVP模式的候选列表长度为2）\n- **构建MVP候选列表的方式也不同**\nAMVP的候选列表长度为2，候选MV总共有4种类型：\n\n-- 基于相邻块的空域MVP\n-- 基于同位块的时域MVP\n-- 基于历史信息构建的HMVP\n-- 零MV\n\n## 2.1 常规AMVP模式\nAMVP是针对运动矢量信息的差分编码技术。利用空域、时域上运动矢量的相关性，为当前CU建立MVP候选列表，和Merge不同，AMVP在构建候选MVP候选列表的时候，针对不同参考图像得到的MVP列表可能不同，需要编码参考帧索引，还需要编码选中MVD列表缩影和MVD(MV-MVP)。AMVP列表针对每个参考图像建立，每个列表各项只包含单项运动信息，且列表长度仅为2。\n\n\n### 2.1.1 空域候选MVP\nVVC的AMVP模式规定,只能从当前PU的左侧和上方各产生一个候选MV，最多允许2个空域候选MV，左侧的检查顺序是A1->A0，上侧的检查顺序是B1->B0->B2。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/fa1f18232ad84ba686c82dbafb8b596b.png)\n\n### 2.1.2 时域候选MVP\n与merge类似\n### 2.1.3 基于历史的候选MVP\n从HMVP中最近4项进行选择\n### 2.1.4 零值MVP\n\n\n## 2.2 对称运动矢量差分编码技术（SMVD）\n对于包含双向运动信息的AMVP模式，可以使用对称MVD编码模式。具体的，在编码时，仅需要编码前向MVD0，后向的MVD1可由MVD1=（-MVD0）推导得到。换句话说，对于双向预测，并且参考位于当前帧两侧的情形，前后向运动矢量具有对称一致性，可以采用对称运动矢量差分编码。对称MVD模式(symmetric MVD mode)是VVC中新提出的一种双向预测时MVD语法单元传输模式。在使用对称MVD模式时，在传输双向预测的运动信息时不需要传list0和list1中参考图像的索引和list1的MVD。这些信息可以在解码端生成。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/eaaed86af37f4cc4bffa619fcaf37336.png)\n**使用条件**\n- AMVP候选包含双向运动信息\n- 当前CU的前向参考帧列表List0中距离最近的参考图像和后向参考帧列表List1中距离最近的参考图像正好处于当前图像的两侧\n\n**解码过程 **\n对称MVD模式的解码过程如下：\n\n1、在slice层，变量BiDirPredFlag, RefIdxSymL0和RefIdxSymL1按如下方式生成：\n\n- 若mvd_l1_zero_flag=1，则BiDirPredFlag=0\n- 否则，如果在list0中离当前图像最近的参考图像和在list1中离当前图像最近的参考图像分别是前向参考图像和后向参考图像对或分别是后向参考图像和前向参考图像对，且list0和list1的参考图片都是短期参考图片，则BiDirPredFlag=1。否则，BiDirPredFlag=0\n\n2、在CTU层，如果CU是双向预测且BiDirPredFlag=1，则需要在码流中显示传输一个对称模式标识符来表明是否使用对称模式。\n\n当对称模式标识符为真时，在码流中只需要传mvp_l0_flag, mvp_l1_flag和MVD0。list-0和list-1的参考索引分别被设置为等于该对参考图片。MVD1=（-MVD0）最终运动向量可由下式生成：\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/97ea8ec139a349059fef521796264c9e.png)\n在解码端MVD1由MVD0的相反数生成，如下图所示。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/095a430b8f084d3fa2d40f5706a3b77b.png)\n在编码端进行对称MVD模式的运动估计时需要一个初始MV。这个初始MV是从单向运动搜索MV、双向运动搜索MV和AMVP list中选择率失真代价最小的MV得到。 \n\n\n\n采用SMVD的时候，前后向参考图像直接选择两个参考图像列表中距离当前图像最近的，并且时间上处于当前图像两侧的短期参考图像。这样可以有效节省前向MV的参考图像索引、后向图像索引、后向MVD编码消耗的比特数。只需要编码双向AMVP候选列表索引、前向运动矢量差MVD。过程如下：\n\n分别获取两个参考图像列表中距离当前帧最近的短期参考图像，得到当前CU的前后向参考图像\n根据前后向参考图像索引RefIdxSymL0和RefIdxSymL1分别建立前向AMVP候选列表和后向AMVP候选列表\n根据MVP列表缩影，得到双向MVP\n根据码流得到前向MVD，推断得到后向MVD\n计算得到MV\n\n## 2.3 自适应运动矢量精度（AMVR）\n允许每个CU自适应选择一种精度表示MVD，最高精度为1/16，最低精度为4亮度像素。适用于传输非0MVD的情况吗，如常规AMVP、SMVD、仿射AMVP。使用率失真优化的方法噶判断是否使用AMVR以及采用何种精度。VTM使用快速算法跳过部分MVD精度。\n由于实际运动通常是连续的，因此整像素精度通常不能很好地表示物体的运动。在HEVC中，亮度分量的运动矢量使用1/4像素精度，色度分量的运动矢量使用1/8像素精度；在VVC中，进一步提高了像素精度，亮度分量的运动矢量使用1/16像素精度，色度分量的运动矢量使用1/32像素精度。随着像素精度的增长，预测精度增长，但随之需要大量的编码比特。\n\n综合考虑预测精度和编码比特消耗，VVC提出了自适应运动矢量精度AMVR技术，在CU级对亮度分量MVD采用不同的像素精度进行编码。根据当前CU帧间预测模式的不同，亮度分量MVD编码精度有不同的选取策略：\n\n常规AMVP模式：1/4亮度像素精度，1/2亮度像素精度，整数亮度像素精度或四倍亮度像素精度。\n仿射AMVP模式：1/4亮度像素精度，整数亮度像素精度或1/16亮度像素精度。\n在编码端，需要比较各个精度下的率失真代价并选出代价最小的编码精度作为当前CU的最优精度。为了降低编码端复杂度，避免对每个MVD精度进行四次（Affine AMVP为三次）CU级的率失真代价的比较，在VVC中使用一些快速算法来跳过除了1/4精度以外某些MVD精度的率失真代价检查。\n\n在HEVC中，当Slice header中的use_integer_mv_flag等于0时，编码快的MVD（CU的运动矢量和预测运动矢量之间的差值）以四分之一亮度像素精度进行编码。 在VVC中，引入了CU级自适应运动矢量精度（AMVR）方案。 AMVR允许以不同的精度对CU的MVD进行编码。\n\n根据当前CU的模式（常规AMVP模式或仿射AVMP模式），可以如下自适应地选择当前CU的MVD：\n\n常规AMVP模式：1/4亮度像素精度，1/2亮度像素精度，整数亮度像素精度或四倍亮度像素精度。\n仿射AMVP模式：1/4亮度像素精度，整数亮度像素精度或1/16亮度像素精度。\n只有当前CU具有至少一个非零MVD分量时，才会传输CU级像素精度。 如果所有MVD分量（即参考列表L0和参考列表L1的水平和垂直MVD）均为零，则MVD默认使用1/4亮度像素精度。\n\n对于至少有一个非零MVD分量的CU，第一个标志位表示CU是否使用1/4亮度像素精度。如果第一个标志为0，则不需要传输其余的标志，当前CU的MVD使用1/4亮度像素精度。否则，\n\n对于常规AMVP模式，需要第二个标志位以表示CU使用1/2亮度像素精度或其他MVD精度（整数或四倍亮度像素精度）。在1/2亮度像素精度下，使用6抽头插值滤波器而不是默认的8抽头插值滤波器。如果不是1/2亮度像素精度，则需要第三个标志用来指示当前CU使用整数亮度像素精度还是四倍亮度像素精度。\n对于仿射AMVP模式，第二个标志用于指示是使用整数亮度像素精度还是1/16 亮度像素精度。\n为了确保重建的MV具有同样的精度，在与MVD相加之前，CU的MVP（运动矢量预测）会四舍五入到与MVD相同的精度。MVP向零进行四舍五入（即负MVP向正无穷大舍入，正MVP向负无穷大舍入）。\n\n编码器使用RD检查确定当前CU的MV精度。为了避免总是对每个CU的MVD执行四次精度检查，在VTM11中，除了1/4亮度像素精度外，其余MVD精度的RD检查只能在某些条件下执行。\n\n对于普通AVMP模式，首先计算1/4亮度像素精度和整数亮度像素精度的RD Cost。然后将整数亮度像素精度的RD Cost与1/4亮度像素精度的RD Cost进行比较，以确定是否有必要进一步检验四倍亮度像素精度的RD Cost。如果1/4亮度像素精度的RD Cost远小于整数亮度像素精度，则跳过四倍亮度像素精度的RD检查。如果整数亮度像素精度的RD Cost显著大于先前测试的MVD精度的最佳RD Cost，则跳过1/2亮度像素精度的检查。\n对于仿射AMVP模式，如果在检查仿射Merge/Skip模式、Merge/Skip模式、常规AMVP模式的1/4亮度像素精度和仿射AMVP模式1/4亮度像素精度的率失真代价后未选择仿射帧间模式，则不检查1/16亮度像素精度和整数亮度像素精度的仿射帧间模式。\n此外，在1/16亮度像素级精度仿射帧间模式中，以1/4亮度像素精度仿射帧间模式得到的仿射参数作为搜索起点。\n\n运动场存储\n在VVC中，显式发出信号的运动矢量的最高精度为1/4像素精度。 在某些仿射帧间预测模式中，以1/16亮度像素精度导出运动矢量，以1/16精度执行运动补偿预测。 在内部运动场存储方面，所有运动矢量都以1 / 16亮度精度存储。\n\n对于TMVP和SbTVMP使用的临时运动场存储，与HEVC中的16x16大小粒度相比，VVC以8x8大小粒度执行运动场压缩。\n\nVTM中，MV的精度的定义：\n\n```cpp\nenum MvPrecision\n{\n  MV_PRECISION_4PEL     = 0,      // 4-pel\n  MV_PRECISION_INT      = 2,      // 1-pel, shift 2 bits from 4-pel\n  MV_PRECISION_HALF     = 3,      // 1/2-pel\n  MV_PRECISION_QUARTER  = 4,      // 1/4-pel (the precision of regular MV difference signaling), shift 4 bits from 4-pel\n  MV_PRECISION_SIXTEENTH = 6,     // 1/16-pel (the precision of internal MV), shift 6 bits from 4-pel\n  MV_PRECISION_INTERNAL = 2 + MV_FRACTIONAL_BITS_INTERNAL,\n};\n```\n\n几种模式的像素精度定义：\n\n```cpp\nconst MvPrecision Mv::m_amvrPrecision[4] = { MV_PRECISION_QUARTER, MV_PRECISION_INT, MV_PRECISION_4PEL, MV_PRECISION_HALF }; // for cu.imv=0, 1, 2 and 3\nconst MvPrecision Mv::m_amvrPrecAffine[3] = { MV_PRECISION_QUARTER, MV_PRECISION_SIXTEENTH, MV_PRECISION_INT }; // for cu.imv=0, 1 and 2\nconst MvPrecision Mv::m_amvrPrecIbc[3] = { MV_PRECISION_INT, MV_PRECISION_INT, MV_PRECISION_4PEL }; // for cu.imv=0, 1 and 2\n```\n\n精度转换的代码：\n\n```cpp\n  void changePrecision(const MvPrecision& src, const MvPrecision& dst)\n  {\n    const int shift = (int)dst - (int)src;\n    if (shift >= 0)\n    {\n      *this <<= shift;\n    }\n    else\n    {\n      const int rightShift = -shift;\n      const int nOffset = 1 << (rightShift - 1);\n      hor = hor >= 0 ? (hor + nOffset - 1) >> rightShift : (hor + nOffset) >> rightShift;\n      ver = ver >= 0 ? (ver + nOffset - 1) >> rightShift : (ver + nOffset) >> rightShift;\n    }\n  }\n```\n\n> 3. 基于子块的帧间预测技术\n# 三、基于子块的帧间预测技术\n视频内容包括平移、旋转、缩放、拉伸运动，利用基于子块的帧间预测模式将CU划分为多个子块，利用CU的运动信息按一定规则得到每个子块不同的运动信息，可以节省此类运动信息所包含的比特数。之前的帧间预测的运动估计仅考虑了简单的平移运动，但在自然界中还存在缩放、旋转、透视等运动，如果仅使用之前的平移运动模型，无法有效表示缩放等运动。\n\n研究发现，仿射（Affine）运动模型能够很好地描述自然界中的非平移运动，VVC中引入了基于块的放射运动补偿技术，包括四参数模型和六参数模型。具体地，利用块中的两个控制点（四参数模型）或者三个控制点（六参数模型）的MV，来推导出整个块中每个4x4子块的MV，之后分别根据每个子块的MV通过运动补偿得到每个子块的预测值。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/066907087ddd442ca32e9ddaeac7435b.png)\n和传统的帧间预测模式类似，Affine模式也分为Affine Merge模式和Affine AMVP模式，Affine Merge模式是通过空间相邻的CU运动信息得到控制点的MV；Affine AMVP模式是根据空间相邻的CU运动信息预测控制点的MV，再以预测的CPMV作为搜索起点进行运动估计，得到最佳的CPMV，并将二者的差值和预测CPMV在候选列表中的索引传给解码端。\n##  3.1 基于子块的时域MV预测技术（SbTMVP）\n使用同位图像ColPic中参考块的运动信息直接得到当前CU子块的MV信息，在当前片是P片时为每个子块构造一个单项预测TMVP，在当前片为B片时为每个子块构造一个双向预测TMVP。当前CU各子块的运动信息由相应同位子块推导得到，当同位子块的运动信息不同时，子块运动信息也不同。\n\n-- 获取同位运动偏移\n-- 获取中心运动信息\n-- 获取子块运动信息：针对内部子块推导得到对应的TMVP\n-- 基于子块的仿射运动补偿\n运动具有一定的规律性，可以统一通过仿射变换的思想。即块内任意像素的运动矢量可以由已知固定像素的运动矢量确定。\n\n有4、6参数仿射模型，只需要编码CU控制点的运动矢量，根据模型公式就可以推导出CU内所有秀昂宿的运动矢量。VVC为每个4x4亮度子块推导一个共用的与i你懂矢量，以中心位置推导得到的运动矢量。并给出了内存访问带宽限制机制和回退模式。\n\n与HEVC中的时间运动矢量预测（temporal motion vector prediction, TMVP）类似，SbTMVP使用同位图片中的运动场来改善当前图片中CU的运动矢量预测和Merge模式。不同的是，sbTMVP预测的是子CU级的运动。\n\nSbTMVP中使用的子CU大小固定为8x8，SbTMVP模式仅适用于宽度和高度都大于或等于8的CU。\n\n在VVC中，SbTMVP和Affine Merge的候选是共存的，将SbTVMP得到的候选和仿射Merge候选共同组成基于子块的Merge候选列表。 通过序列参数集（SPS）标志启用/禁用SbTVMP模式。 如果启用了SbTMVP模式，则将SbTMVP预测变量添加为基于子块的Merge候选列表的第一项，然后是仿射Merge候选项。\n\n将sbTMVP和Affine Merge共同的候选列表称为基于子块的Merge列表，其大小在SPS中用信号通知，并且基于子块的Merge列表的最大允许大小为5。\n\n\n\n> 仿射Merge模式\n### 3.2、仿射Merge模式\n在基于子块的仿射运动补偿的基础上，各控制点的运动矢量（CPMV）由SubBlkMergeMVP列表直接得到，是merge的扩展模式。列表中每项候选项包含多个运动矢量，由空间、时间相邻CU的运动信息生成。\n\n**SubBlkMergeMVP列表**\n\n空间相邻仿射模式CU继承候选：最多包含2个，左侧相邻块扫描顺序A0-A1，上册相邻块为B0-B2，每侧采用一个使用仿射模式编码的CU来推导CPMVP候选。\n\n空域和时域相邻CU的平移MV构造：设置4个控制点备选。查表组合得到候选CPMVP\n零值MV填充\n\n对于宽度和高度大于等于8的CU， 可以使用Affine Merge模式。Affine Merge模式中，控制点的运动矢量CPMV是根据空域相邻CU的运动信息生成的，最多有五个候选项，有以下五种方式生成CPMV的候选：\n\n继承Affine Merge候选项：直接继承其相邻CU的CPMV候选项（最多有两个候选项，上相邻CU最多一个，左相邻CU最多一个）\n构造Affine Merge候选项：使用相邻CU的平移运动的MVs构造CPMVPs候选项（不限个数，直至填充够5个）\n零MV（若不足5，则填充）\n\n### 3.3、仿射AMVP模式\n当仿射merge无法得到有效的控制点运动矢量的时候使用。针对指定的参考图像，利用仿射AMVP列表得到CPMV的预测值CPMVP，结合对应控制点MVD（MvdCp）表示CPMV。需要将单双向运动信息，包括参考索引、CPMVP列表索引、对应的Mvdcp，和预测残差一起送入码流。\nAffine AMVP模式可应用于宽度和高度均大于或等于16的CU。在Affine AMVP模式下，需要传输其预测CPMV在候选列表中的索引以及它和运动搜索得到的实际CPMV的残差。Affine AVMP候选列表大小为2，它是通过依次使用以下5种CPMV候选类型生成的：\n\n1. 继承AMVP候选项：继承其相邻CU的CPMV候选项\n2. 构造Affine AMVP候选项：使用相邻CU的平移运动的MVs构造CPMVPs候选项\n3. 直接使用相邻CU的平移MV\n4. 同位块的时域MV\n5. 零MV\n\n**仿射AMVP模式列表**\n**1. 空域相邻仿射模式CU继承**：根据采用仿射模式的空域相邻CU的CPMV推导得到CPMVP候选。\n**2. 空域相邻CU的平移MVP构造**：根据MV平移得到\n**3. 空域相邻CU的平移MV填充**\n**4. 时域平移MV填充**\n**5. 零值MV填充**\n\n> 帧间后处理技术\n# 四、帧间后处理技术\n为了进一步提高帧间预测的准确性，VVC采用了多种帧间预测后处理技术值，以修正帧间预测的预测像素，提高预测性能。\n主要包含三个技术：\n\n- DMVR技术：用于修正常规Merge模式双向预测MV，以Merge列表中的双向MV为初始MV，在一定范围内镜像搜索，以获得更精确的MV。\n- BDOF技术：使用双向光流技术来修正双向预测的预测值。\n- PROF技术：使用光流技术来细化基于子块的Affine运动补偿预测。\n\n## 4.1 解码端运动矢量细化（DMVR）\nmerge模式可以高效表示运动矢量信息，但可能会导致其运动矢量并非使参考块与编码块最匹配。所以VVC采用了一种双边匹配的解码端运动矢量细化技术。\n\n正对采用双向预测merge模式的CU，可以直接得到前后向运动矢量MVL0\\MVL1。以对称的方式，给这两个运动矢量加一个小的偏移量MV_diff。基本过程：\n\n参考块获取，根据前后向运动矢量，对每个子块实施运动补偿得到前后向参考块，并对前后向参考子块进行扩充。\n整像素搜索：通过计算前后向参考子块的SAD衡量其匹配程度，找到最小的对应MV_diff作为整像素搜索的最优MV整像素精度偏移量。\n亚像素计算：亚像素精度MV_diff并不搜索MV_diff周围的亚像素位置，而是基于二次误差曲面函数计算得到。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/425efb89c8704224aadcc76797b8a9df.png)\n## 4.2 基于光流场的预测值修正\n光流指视频帧内容在时域上的瞬时运动速度，即像素在时间域上的运动速度。时间较短的两帧，光流也表现为统一目标点在两帧之间位移，即像素的运动矢量。所以可以利用图像帧中像素亮度在时间域上的变化及像素空域相关性，计算视频帧之间的像素运动信息。因此可以根据参考像素值、光流值、空域梯度得到。当运动补偿中运动矢量存在较小误差时，可以计算运动矢量误差，利用预测值进行修正。\n\n## 4.3 双向光流预测值修正(BDOF)\n采用参考帧对称的帧间双向预测的编码块，前、后向预测参考块和当前编码块间的光流对称。可以根据光流公式推到i计算解决一个优化问题：对齐后前后向预测参考块应一致。可以求出双向预测得到的预测值，和双向光流补偿值，得到当前块的补偿光流。为4x4的子块估计一个光流。\n\n子块获取：包括padding预处理\n子块亮度空域梯度和时域梯度的计算：根据公式计算\n光流计算：VVC采用了简化的光流计算方式\n补偿值计算：进一步得到每个像素的光流修正值\n###  4.4 基于光流的仿射预测修正\n针对采用仿射运动补偿的编码块，光流预测细化技术为4x4子块的每个像素计算光流补偿值，即像素运动矢量和子块运动矢量的插值，然后计算每个像素的亮度补偿值。\n### 4.5 子块光流计算\n子块亮度空域梯度计算\n亮度补偿值计算：利用空间梯度和光流补偿值，计算每个像素的亮度补偿值\n\n# 五、帧间加权预测\nSlice级加权预测\n由于光强造成全局或者局部的亮度变化，但是这类相邻图像内容依旧相似，但在像素值上无法反应，所以对于亮度整体渐变的场景，slice级加权预测可以有效应对，对参考图像的重建像素值做一个线性变换得到预测值。\n\n可以用于单项预测也可以用于双向预测，slice内所有CU采用其中一组或者两组加权参数。\n\n## 5.1、CU级双向加权预测（BCW）\n仅对双向预测CU开启，使用少量预定义的权值，且不同配置下权集不同，编码索引。\n在VVC中，双向预测模式可以对两个预测信号进行加权平均。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/c97c4b5f682247069479bb61fac0aa94.png)\n其中w为权重，总共包含5个权重，w∈{-2,3,4,5,10}。权重由预测模式确定。\nBCW仅适用于具有256个或更多亮度像素的CU（即CU宽度乘以CU高度大于或等于256）。\n\n## 5.2、加权预测（WP）\n加权预测用于修正P Slice或B Slice中的运动补偿预测像素，加权预测表示预测像素可以用一个（适用于P Slice情况）或者两个（适用于B Slice情况）参考图像中的像素通过与加权系数相乘得出，如下：\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/bf8a12be68ad466fb88b489843c4d74d.png)\n加权预测适用于两图像之间像素值整体变化且有相同变化规律的情形，如淡入、淡出等效果。\n加权预测（WP）用于帧级加权，双向加权预测（BCW）用于CU级。加权预测WP既可用在双向预测，也可用在单向预测；双向加权预测BCW仅可用在双向预测。\n\n# 六、帧间预测模式组织结构\nVVC中使用了大量的帧间编码技术，但是编码选取帧间预测模式也需要消耗很多比特。所以设计了树形结构来编码该模式的使用。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/93db67fdb6c04f4697c891b0d46a7e6a.png)\n\n> 运动估计\n# 七、运动估计\n由于视频中通常存在很多运动物体，因此简单地将相邻帧的同位像素作为预测值的预测精度并不高，因此，通常使用运动估计来掌握运动物体的运动情况。通过运动估计，可以在参考帧中找到一个最佳匹配块，最佳匹配块到当前块的位移即为运动矢量，得到运动矢量之后，就可以通过运动补偿得到当前块的预测值。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/d64227c9fe584490a5076172ac489465.png)\n运动估计要求当前块在参考帧中某一范围内，找出最佳的匹配块，目前主流标准中常用的匹配准则是SAD准则和SATD准则，即\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/242e1bb37aaa465da825c1478cad2e51.png)\nSAD(s,p)表示的是原始块s和匹配块p的绝对误差和，λmotion\n表示编码运动信息（如MV、参考图像索引）等所需的比特数，λmotion\n为运动估计过程中的拉格朗日因子\n\n由于运动搜索算法复杂度非常高，所以编码器里常用的是快速运动搜索算法。在自然界中，物体的运动具有一定的连续性，所以相邻的两幅图像之间的物体运动可能并不是以整数像素为单位的，而有可能是1/2 像素，1/4 像素等等分像素单位。此时若依然使用整数像素进行搜索，则会出现匹配不准确的问题，导致最终的预测值和实际值之间的残差过大，影响编码性能。因此，近年来视频标准中常采用分像素运动估计，即首先对参考帧的行和列方向进行插值，对插值后的图像中进行搜索。HEVC采用1/4像素精度进行运动估计，VVC中采用1/16像素精度运动估计。\n\nH.266/VVC的参考软件平台VTM中使用TZSearch搜索算法进行运动估计。\n![TZSearch算法中的菱形搜索模板](https://i-blog.csdnimg.cn/direct/e0d201b43a2749fdb3dfd62ae37e10b4.png)\n![TZSearch算法中的正方形搜索模板](https://i-blog.csdnimg.cn/direct/5f2c32d3ee2543858767068844df65e6.png)\nTZSearch算法的步骤：\n\n①确定搜索起始点：VVC中采用AMVP技术来确定起始搜索点，AMVP会给出若干个候选预测MV，编码器从中选择率失真代价最小的作为预测MV，并用其所指向的位置作为起始搜索点。 \n\n②以步长1开始，按照上图所示的菱形模板(或正方形模板)在搜索范围内进行搜索，其中步长以2的整数次幂的形式进行递增，选出率失真代价最小的点作为该步骤搜索的结果。\n\n③若步骤②中得到的最优点对应的步长为1，则需要在该点的周围进行两点搜索，其主要目的是补充搜索最优点周围尚未搜索的点。如下图所示，若步骤②使用的是菱形模板，则最优点可能是2、4、5、7；若步骤二使用的是正方形模板，则最优点可能为1~8。两点搜索将会搜索图中与当前最优点距离最近的两个点。例如，若最优点为2，则会搜索a,b两个点；若最优点为6，则会搜素e,g两个点。\n\n\n\n④若步骤②中得到的最优点对应的步长大于某个阈值，则以该最优点为中心，在一定范围内做全搜索，即搜索该范围内的所有的点，选择率失真代价最小的作为该步骤的最优点。 \n\n⑤以步骤四得到的最优点为新的起始的搜索点，重复步骤二到步骤四，细化搜索，当相邻两次细化搜索得到的最优点一致时停止细化搜索，此时得到的MV即为最终的MV。\n\n\n\n\n> 运动补偿\n\n# 八、运动补偿\n**几何划分帧间预测技术GPM模式**需要对划分边缘进行加权渐变处理与多种帧间预测模式同时应用的光流场修正、片级运动补偿(WP)、CU级权重的加权预测（BCW）等预测块处理技术\n\n**帧间编码信息的存储**\n需要存储除了参考帧、MV水平分量、MV垂直分量，还有半像素插值滤波器索引、CU级权重双向加权预测的权重索引、用于放射模式的局部多控制点MV信息、参考图像的MV信息。\n\n**亚像素插值**\nVVC采用双线性插值方法，插值滤波器为一维滤波器，按照先水平方向后垂直方向的顺序完成二维亚像素插值。\n用于提升运动矢量精度也用来防止当前帧与参考帧分辨率不同的情况。\n\n插值滤波器选择\n（1）亮度分量：最高支持1/16像素精度插值，统一为8抽头滤波器。\n（2）色度分量：最高支持1/32像素精度插值，统一使用4抽头滤波器。\n\n水平、垂直滤波器的系数分别由水平、垂直方向的缩放因子决定，最后通过查表的方式获得插值滤波器的系数。","tags":["vvc"],"categories":["developer"]},{"title":"深度解析H.266/VVC帧内编码","url":"/2024/07/20/深度解析H-266-帧内编码/","content":"\n预测编码（Prediction Coding）是指利用已编码的一个或多个样本值，根据某种模型或方法，对当前的样本值进行预测，对样本真实值和预测值之间的差值编码。视频中的每个像素看成一个信源符号，它通常与空域上或时域上邻近的像素具有较强的相关性，因此视频是一种有记忆信源。预测编码技术通过预测模型消除像素间的相关性，得到的差值信号可以认为没有相关性，或者相关性很小，因此可以作为无记忆信源进行编码。\n\n视频预测编码的主要思想是通过预测来消除像素间的相关性；主要分为帧内预测和帧间预测。\n**帧内预测**：利用当前图像内已编码像素生成预测值。\n**帧间预测**：利用当前图像之前已编码图像的重建像素生成预测值。\n\n# VVC 帧内预测编码过程\n帧内预测技术是利用同一帧中相邻像素的相关性，利用当前块相邻区域的重建像素预测当前块中像素的技术，如下图所示，当前CU可以利用相邻A、B、C、D和E位置处的重建像素来预测当前CU中的像素。通过帧内预测之后，再将预测残差通过变换、量化等，可以有效地去除视频的空间冗余。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/ab92afa4bd3d41a494f4523f146e666f.png)\n帧内预测是利用的视频的空间相关性，利用当前图像已经编码的像素预测当前像素，VVC的帧内预测方法主要分为两种方式：\n\n- 利用相邻（左边和上方）已经编码的像素预测当前像素（如角度预测模式）\n- 利用已经编码的颜色分量预测当前颜色分量的像素（如CCLM模式，用Y分量的像素预测色度分量的像素）\n\n为了提高帧内预测模式的性能，VVC中的帧内预测模式改进主要有以下几点：\n引入了更大尺寸的预测块\n- 为了提高预测的精度，引入了更多的参考像素（MRL多参考行模式），针对参考像素的处理，使用了新的滤波技术（MDIS）\n- 引入了更多的方向性（65种角度预测模式）\n- 引入了跨分量预测（CCLM模式）\n- 引入了神经网络的思想（MIP技术）\n- 对预测后的像素进一步改进（PDPC技术）\n- 更小预测和变换块（ISP技术）\n\n\n# 一、角度预测模式\n为了捕捉自然视频中呈现的更多的边缘方向，VVC在HEVC的33个角度预测模式的基础上，将角度预测模式扩展到了65个，再加上Planar模式和DC模式，共67个传统角度模式。\n\n角度预测模式的步骤为：\n## 1.1 参考像素获取\n参考像素值获取模块是对当前CU相邻参考像素是否可用进行判断。\n\nH266沿用大范围边界像素作为当前CU的参考，当参考像素不可用或不存在时使用默认值填充的方式得等到参考像素值。\nH266引用多参考行内预测（Multiple Reference Line Intra Prediction， MRLP）技术，领域像素可选范围扩展到当前CU上侧三行和左侧三列。得到邻域像素后，进行平滑滤波或差值滤波，引入依赖模式的帧内平滑（Mode Dependent Smoothing，MDIS）技术，根据预测模式和CU尺寸进行不同的滤波处理。\n\n![VVC帧内预测模板](https://i-blog.csdnimg.cn/direct/3fc97b3215d740c8889d6800f95c7f6b.png)\n\n## 1.2 参考像素范围\n1.  **单参考行像素**\n    -  当参考像素不存在或者不可用时（比如图像边界、Slice边界、Tile边界或尚未编码块），H266使用最邻近的像素进行填充，比如下图A的参考像素不存在，则A所有像素都用B的最下方的像素进行填充。\n    -  如果所有区域参考像素都不可用，则用固定值填充；Mid=1<<(bitdepth-1)；\n     - 如果像素比特深度是8，则固定值是128，如果是10，则固定值是512；例如第一个CU的参考像素就是用固定值填充。\n ![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/6a485539a7ec4bcbaf2efc46d89ade90.png)\n\n\n2.  多参考行像素（MRLP）\n    MRLP技术允许使用邻近的3行（列）参考像素，选择其中的1行（列）生成预测值，对于不存在或者不可用的像素，采用于单行相同的填充方式。为了平衡性能，仅允许MPM列表中的模式使用MRLP技术。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/4a385793825f4e17835b2e4bdb06b4a9.png)\n\n## 1.3 参考像素平滑滤波（MDIS）\n在HEVC中，对角度预测模式（不包括Planar和DC）使用两抽头线性插值滤波器进行滤波。\n在VVC中，采用四抽头高斯插值滤波器来进行滤波，从而提高帧内角度预测精度。\n\nVVC协议中MDIS 帧内参考像素滤波总共存在三种滤波器，即满足条件下的整数平滑滤波、非整像素下的三次插值滤波器、非整像素的高斯插值滤波器。\n\n- 一种是对满足一定条件下的参考像素进行平滑滤波 ([1 2 1]/4 滤波器)；\n- 另外两种是对预测时非整数像素位置的插值滤波器，VVC共使用两组四抽头的插值滤波器：三次插值滤波器和高斯插值滤波器，其中三次插值滤波器能保留更多细节纹理，高斯插值滤波器的滤波效果更为平滑。\n\n\n1. **整数平滑滤波**\n是否对参考像素进行滤波由当前CU的大小、预测模式等条件，需要同时满足如下表格中的五个条件才能使用平滑滤波。\n滤波方法为3抽头滤波器，抽头系数为[0.25， 0.5， 0.25]。\n\n| 序号 | 条件                                                 |\n| :--: | :--------------------------------------------------- |\n|  1   | 参考行限制：预测过程使用单参考行像素                 |\n|  2   | 大小限制：预测过程使用单参考行像素                   |\n|  3   | 仅对亮度分量使用                                     |\n|  4   | 不适用ISP模式                                        |\n|  5   | 模式限制：当前CU选择的模式属于Planar模式或者对角模式 |\n\n2. **三次插值滤波器**\n在非整像素可以保留更多的细节纹理，满如条件中（使用了MRLP技术或ISP技术、使用了Planar模式或对角模式、 Distmin <=Thr[n] ）其中一个即可使用。\n\n4. **高斯插值滤波器**\n滤波效果更加平滑，应用更加广泛，不满足三次插值滤波器时使用。\n\n\n# 二、预测值计算\n根据参考像素值，采用特定的预测模式计算待编码CU每个像素的预测值。\n\n- H266将角度预测模式扩展到了65种，加上DC模式和Planar模式一共67种模式称为传统预测模式。\n- 针对宽高不等的方形CU，宽角度帧内预测（Wide Angle Intra Prediction，WAIP）技术表达了更多的预测方向，模式编码扩展[-14, 80]。\n- H266还引入了基于矩阵的帧内预测（Matrix-based Intra Prediction，MIP）技术，借助神经网络离线训练得到的多个权重矩阵生成预测值，对传统预测模式有效补充。\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/aa92ce184d86484fb9b31f5fe71cd3b1.png)\n\n\n## 2.1 Planar模式\n编号0，适用于像素值缓慢变化的区域，其预测像素可以看成是水平、垂直两个方向预测值的平均值。\n## 2.2 DC 模式\n编号1，适用于大面积平坦区域，DC模式需要计算出当前CU左侧及上方参考像素的平均值。\n## 2.3 传统角度预测模式\n位于-135°~45°内，水平类模式编号为2 ~ 33，垂直类编号34 ~ 66；每种角度预测模式都相当于在水平或垂直方向做了角度偏移，如下表。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/8db351609af64f9ab18cabefdc68ba87.png)\n为了捕捉自然视频中呈现的任意边缘方向，VVC中的帧内传统角度预测模式数从HEVC中使用的33个扩展到65个。\n在下图中，VVC中的新的角度预测模式被描绘成红色虚线箭头，并且planar和DC模式保持不变。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/aed2cd308243473c83b9298cf2ab3918.png)\n在HEVC中，每个帧内编码块都是正方形的且每边的长度是2的幂，因此，使用DC模式进行帧内预测时不需要除法运算。\n在VVC中，帧内编码块可以是矩形，为了避免用DC模式进行帧内预测时需要进行除法运算，VVC只计算较长一边的均值作为预测值。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/7ca7a4328935475b85a069b15dd68415.png)\n## 2.4 宽角度预测模式\n在HEVC中，由于帧内预测块都是正方形的，所以各个角度预测模式使用的概率是相等的。\n在VVC中，帧内预测块可能是矩形块，对于水平类的块（宽大于高）上边的参考像素使用概率大于左边参考像素的使用概率，对于垂直类的块（高大于宽）上边的参考像素使用概率小于左边参考像素的使用概率。\n\n因此，VVC引入了宽角度预测模式，在对矩形块预测时，将传统的角度预测模式转换为宽角度预测模式。\n如图，模式2 ~ 66表示传统的帧内预测模式，模式 -1 ~ -14以及模式67 ~ 80表示宽角度预测模式。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/37ec2ce82df64e90a2847468dc52322c.png)\n宽角度预测模式仍然使用传统角度模式索引发出信号，在解码端在将传统角度模式再转换为宽角度预测模式，这样的话帧内预测模式的总数和帧内模式编码方法保持不变, 并且帧内模式编码方法不变。\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/63926bc7c2a9418286c2c8b41d60d716.png)\n在H266中，二叉树划分和三叉树划分都会导致非方形CU的出现，传统的角度模式范围可能会限制非方形CU对参考像素的选择。\n相应的角度偏移如下表。针对非方形CU，增加宽角度预测模式后，仍使用65重候选角度预测模式，即增加的宽角度预测模式替换了部分传统角度预测模式；一般会根据宽高比来替换不同的传统角度编号。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/b03d6705715f4251bb3cf12cb4e19442.png)\n\n\n宽角度帧内预测模式的替换取决于块的宽高比。\n具体如下表所示：\n\n|    宽高比     |                  被替换的角度模式                  |                       替换后的角度模式                       |\n| :-----------: | :------------------------------------------------: | :----------------------------------------------------------: |\n|  W / H == 16  |      Modes 2,3,4,5,6,7,8,9,10,11,12, 13,14,15      | Modes 67，68，69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80 |\n|  W / H == 8   |         Modes 2,3,4,5,6,7,8,9,10,11,12, 13         |     Modes 67，68，69, 70, 71, 72, 73, 74, 75, 76, 77, 78     |\n|  W / H == 4   |            Modes 2,3,4,5,6,7,8,9,10,11             |         Modes 67，68，69, 70, 71, 72, 73, 74, 75, 76         |\n|  W / H == 2   |               Modes 2,3,4,5,6,7,8,9                |                 Modes 67，68，69, 70, 71, 72                 |\n|  W / H == 1   |                        None                        |                             None                             |\n| W / H == 1/2  |           Modes 59,60,61,62,63,64,65,66            |                 Modes -6，-5，-4，-3，-2，-1                 |\n| W / H == 1/4  |         Mode 57,58,59,60,61,62,63,64,65,66         |           -10，-9，-8，-7，-6，-5，-4，-3，-2，-1            |\n| W / H == 1/8  |     Modes 55, 56,57,58,59,60,61,62,63,64,65,66     |      -12，-11，-10，-9，-8，-7，-6，-5，-4，-3，-2，-1       |\n| W / H == 1/16 | Modes 53, 54, 55, 56,57,58,59,60,61,62,63,64,65,66 | Modes\t-14，-13，-12，-11，-10，-9，-8，-7，-6，-5，-4，-3，-2，-1 |\n\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/3cb5191642ce499c80cdb9698bd1a8f9.png)\n如上图所示，当对矩形块使用宽角度预测时，垂直相邻的两个预测像素可能使用两个不相邻的参考像素。\n为了减少参考像素间距∆pα带来的负面影响，需要对参考像素进行低通滤波和平滑处理。\n当预测模式是[-14, -12, -10, -6, 72, 76, 78, 80]时，参考像素可以不经处理直接使用。\n\n角度模式向宽角度模式的转换代码如下所示：\n\n```cpp\nint PU::getWideAngle( const TransformUnit &tu, const uint32_t dirMode, const ComponentID compID ){\n  //This function returns a wide angle index taking into account that the values 0 and 1 are reserved \n  //for Planar and DC respectively, as defined in the Spec. Text.\n  if( dirMode < 2 )\n  {\n    return ( int ) dirMode;\n  }\n \n  const CompArea&  area         = tu.cu->ispMode && isLuma(compID) ? tu.cu->blocks[compID] : tu.blocks[ compID ];\n  int              width        = area.width;\n  int              height       = area.height;\n  int              modeShift[ ] = { 0, 6, 10, 12, 14, 15 };\n  int              deltaSize    = abs( floorLog2( width ) - floorLog2( height ) );\n  int              predMode     = dirMode;\n \n  if( width > height && dirMode < 2 + modeShift[ deltaSize ] )\n  {\n    predMode += ( VDIA_IDX - 1 );\n  }\n  else if( height > width && predMode > VDIA_IDX - modeShift[ deltaSize ] )\n  {\n    predMode -= ( VDIA_IDX + 1 );\n  }\n \n  return predMode;\n}\n```\n\n\n## 2.5 基于矩阵的预测模式(MIP)\n传统预测模式及宽角度预测模式都是以像素映射或线性渐变方式计算预测值，无法对不规则纹理做出有效的预测。\nH266标准使用了MIP技术，采用离线训练神经网络的方法，得到多个固定的权重矩阵，进而利用权重矩阵计算预测值。\n参考像素经过处理后得到输入向量，输入向量与权重矩阵相乘得到输出向量，经过进一步排列和上采样得到待编码CU的预测值。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/85a03502c0c248c8877f0ed078c57a21.png)\n\n\n# 三、 预测值修正\n## 3.1 位置决定的帧内预测组合(PDPC)\n## 3.2 帧内子区域划分(ISP)\nISP技术旨在充分利用与待预测像素距离相近的参考像素进行预测。\n根据编码块得到大小，将亮度帧内预测块垂直划分或水平划分为若干个子区域，并按照从左到右、从上到下的额顺序依次进行编码及重建。\nISP技术使帧内预测编码基于CU子区域进行，前一子区域编码之后的重建像素为下一子区域提供参考，各子区域共用一种帧内预测模式。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/e878ac1aa0a04d1d8de9db1c8fe660f3.png)\n## 3.3  跨分支线性模型预测(CCLM）\n在H266中，CU色度分量进行预测编码前，亮度分量已经完成编码获得亮度重建值，因此亮度分量可以作为色度分量预测的参考信息。CCLM技术通过参考像素的亮度重建值和色度重建值建立分量间线性关系，根据待预测像素的亮度重建值计算色度预测值，过程如下图。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/abd32af3615a46b8ba2242b1d60c1260.png)\n## 3.4 亮度分量的最可能模式（Most Probable Mode，MPM）技术\nMPM技术充分利用相邻块预测模式之间的相关性，来进行亮度预测模式的编码。\n如果直接对预测块的模式进行编码，那么对于67种模式需要7bit来编码，数据量很大。\n\nVVC采取和HEVC一样的方法，先构建最可能模式列表（most probable mode ，MPM）\n在VVC内MPM list里有6个预测模式（无论是否应用MRL和ISP），\n\n- 如果该块的预测模式在MPM中只需要编码其索引号（只需要3bit），\n- 如果该块的预测模式不在MPM中而是在61个non-MPM模式中，熵编码时使用截断二元码（TBC)编码其模式。\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/a5a793e0a31840f0959ff79459a2e7cc.png)\nMPM列表是基于左边相邻块和上方相邻块的帧内模式构造的，如上图所示，构造方法如下：\n\n- 当左边块和上边块不可参考时，其帧内模式默认设置为Planar模式\n\n- 如果左边块和上边块都是非角度模式时， MPM list -> {Planar，DC，V，H，V--4，V+4}\n\n- 如果左边块和上边块其中一个是角度模式，另一个不是角度模式时\n    设Max是左边块和上边块较大的模式 , MPM list ->{Planar, Max, Max − 1, Max + 1, Max − 2, Max + 2}\n    \n- 如果左边块和上边块都是角度模式且它们不同时\n\t设Max是左边块和上边块较大的模式\n\t设Min是左边块和上边块较小的模式\n\t- 如果Max - Min 的等于 1,  则 MPM list -> {Planar, Left, Above, Min – 1, Max + 1, Min – 2}\n\t- 如果Max - Min 的大于等于62, 则MPM list ->{Planar, Left, Above, Min + 1, Max – 1, Min + 2}\n\t- 如果Max - Min 的等于2 则MPM list -> {Planar, Left, Above, Min + 1, Min – 1, Max + 1}\n                                        否则MPM list -> {Planar, Left, Above, Min – 1, –Min + 1, Max – 1}\n- 如果左边块和上边块时相同的角度模式时，\n                                       MPM list –>{Planar, Left, Left − 1, Left + 1, Left − 2, Left + 2}}\n\nMPM索引码字的第一个bin是CABAC上下文编码的。\n总共使用三个上下文，分别对应于当前帧内块是启用了MRL、启用了ISP还是正常的帧内块。\n生成MPM列表时候，需要删除重复的模式，以便包含在MPM列表的模式唯一。\n\n具体建立过程：\n1. 获得左下和右上相邻像素，分别记为A和B\n![在这里插入图片描述](https://i-blog.csdnimg.cn/direct/912b8e5586904b008e10c1e136e93d66.png)\n2. 获取相邻像素A和B所在PU的帧内预测模式，获取方法如下：\n\n- 如果以下条件之一成立，则相邻PU的帧内预测模式设置为Planar模式 \n- 其相邻PU不可用\n- 相邻PU的编码模式不是帧内编码模式\n- 相邻PU是MIP模式\n- 相邻PU和当前PU不是位于同一个CTU\n- 否则，获取其相邻PU的帧内预测模式\n\n3. 将相邻像素A、B所处PU的预测模式分别记为A、B，则MPM列表构建如下：\n(1) A =B 且 A > B\n\n| MPM[0] |         Planar         |\n| :----: | :--------------------: |\n| MPM[1] |           A            |\n| MPM[2] | 2 + ( ( A +61 ) % 64 ) |\n| MPM[2] | 2 + ( ( A -1 ) % 64 )  |\n| MPM[3] | 2 + ( ( A +60 ) % 64 ) |\n| MPM[4] |    2 + ( A  % 64 )     |\n| MPM[5] |         VER+4          |\n\n(2) A ≠ B，A > DC且B > DC\n记MinAB = Min(A,B), MaxAB = max(A,B)\n\n| MPM[0] | Planar |\n| :----: | :----: |\n| MPM[4] |   A    |\n| MPM[5] |   B    |\n\n- 若maxAB - minAB = 1，则\n\n| MPM[3] | 2+((minAB+61))%64 |\n| :----: | :---------------: |\n| MPM[4] | 2+((maxAB-1))%64  |\n| MPM[5] |   2+(minAB)%64    |\n\n- 若maxAB - minAB >= 62，则\n\n| MPM[3] | 2+((minAB+61))%64 |\n| :----: | :---------------: |\n| MPM[4] | 2+((maxAB-1))%64  |\n| MPM[5] |  2+(minAB+60)%64  |\n\n- 若maxAB - minAB >=62，则\n\n| MPM[3] | 2+((minAB-1))%64  |\n| :----: | :---------------: |\n| MPM[4] | 2+((maxAB+61))%64 |\n| MPM[5] |   2+(minAB)%64    |\n\n- 若maxAB - minAB = 2，则\n\n| MPM[3] | 2+((minAB-1))%64  |\n| :----: | :---------------: |\n| MPM[4] | 2+((minAB+61))%64 |\n| MPM[5] |   2+(maxAB)%64    |\n\n- 否则\n\n| MPM[3] | 2+((minAB+61))%64 |\n| :----: | :---------------: |\n| MPM[4] | 2+((minAB-1))%64  |\n| MPM[5] |  2+(maxAB+61)%64  |\n\n\n(3) A ≠ B，A > DC 或 B > DC\n\n| MPM[0] |           Planar            |\n| :----: | :-------------------------: |\n| MPM[1] |            maxAB            |\n| MPM[2] | 2 + ( ( maxAB + 61 ) % 64 ) |\n| MPM[3] | 2 + ( ( maxAB − 1 ) % 64 )  |\n| MPM[4] | 2 + ( ( maxAB + 60 ) % 64 ) |\n| MPM[5] |     2 + ( maxAB % 64 )      |\n\n(4) 否则\n\n| MPM[0] | Planar |\n| :----: | :----: |\n| MPM[1] |   DC   |\n| MPM[2] |   DC   |\n| MPM[2] |  VER   |\n| MPM[3] |  HOR   |\n| MPM[4] | VER-4  |\n| MPM[5] | VER+4  |\n\n具体代码:\n\n```cpp\nint PU::getIntraMPMs( const PredictionUnit &pu, unsigned* mpm, const ChannelType &channelType /*= CHANNEL_TYPE_LUMA*/ )\n{\n  const int numMPMs = NUM_MOST_PROBABLE_MODES;\n  {\n    CHECK(channelType != CHANNEL_TYPE_LUMA, \"Not harmonized yet\");\n    int numCand      = -1;\n    int leftIntraDir = PLANAR_IDX, aboveIntraDir = PLANAR_IDX;//将左相邻块和上相邻块预测模式设置为Planar模式\n \n    const CompArea &area = pu.block(getFirstComponentOfChannel(channelType));\n    const Position posRT = area.topRight();//当前块的左上角\n    const Position posLB = area.bottomLeft();//当前块的右下角\n \n    // Get intra direction of left PU\n    // 获得左相邻PU\n    const PredictionUnit *puLeft = pu.cs->getPURestricted(posLB.offset(-1, 0), pu, channelType);\n    if (puLeft && CU::isIntra(*puLeft->cu))\n    {\n      leftIntraDir = PU::getIntraDirLuma( *puLeft );//获得左相邻PU的预测模式\n    }\n \n    // Get intra direction of above PU\n    // 获得上相邻PU\n    const PredictionUnit *puAbove = pu.cs->getPURestricted(posRT.offset(0, -1), pu, channelType);\n    if (puAbove && CU::isIntra(*puAbove->cu) && CU::isSameCtu(*pu.cu, *puAbove->cu))\n    {\n      aboveIntraDir = PU::getIntraDirLuma( *puAbove );//获得左相邻PU的预测模式\n    }\n \n    CHECK(2 >= numMPMs, \"Invalid number of most probable modes\");\n \n    const int offset = (int)NUM_LUMA_MODE - 6;//61\n    const int mod = offset + 3;//64\n \n    {\n      mpm[0] = PLANAR_IDX;//Planar\n      mpm[1] = DC_IDX;//DC\n      mpm[2] = VER_IDX;//50\n      mpm[3] = HOR_IDX;//18\n      mpm[4] = VER_IDX - 4;//46\n      mpm[5] = VER_IDX + 4;//54\n \n      if (leftIntraDir == aboveIntraDir)\n      {\n        numCand = 1;\n        if (leftIntraDir > DC_IDX)\n        {\n          mpm[0] = PLANAR_IDX;\n          mpm[1] = leftIntraDir;\n          mpm[2] = ((leftIntraDir + offset) % mod) + 2;\n          mpm[3] = ((leftIntraDir - 1) % mod) + 2;\n          mpm[4] = ((leftIntraDir + offset - 1) % mod) + 2;\n          mpm[5] = ( leftIntraDir               % mod) + 2;\n        }\n      }\n      else //L!=A\n      {\n        numCand = 2;\n        int  maxCandModeIdx = mpm[0] > mpm[1] ? 0 : 1;\n \n        if ((leftIntraDir > DC_IDX) && (aboveIntraDir > DC_IDX))\n        {\n          mpm[0] = PLANAR_IDX;\n          mpm[1] = leftIntraDir;\n          mpm[2] = aboveIntraDir;\n          maxCandModeIdx = mpm[1] > mpm[2] ? 1 : 2;\n          int minCandModeIdx = mpm[1] > mpm[2] ? 2 : 1;\n          if (mpm[maxCandModeIdx] - mpm[minCandModeIdx] == 1)\n          {\n            mpm[3] = ((mpm[minCandModeIdx] + offset)     % mod) + 2;\n            mpm[4] = ((mpm[maxCandModeIdx] - 1)          % mod) + 2;\n            mpm[5] = ((mpm[minCandModeIdx] + offset - 1) % mod) + 2;\n          }\n          else if (mpm[maxCandModeIdx] - mpm[minCandModeIdx] >= 62)\n          {\n            mpm[3] = ((mpm[minCandModeIdx] - 1)      % mod) + 2;\n            mpm[4] = ((mpm[maxCandModeIdx] + offset) % mod) + 2;\n            mpm[5] = ( mpm[minCandModeIdx]           % mod) + 2;\n          }\n          else if (mpm[maxCandModeIdx] - mpm[minCandModeIdx] == 2)\n          {\n            mpm[3] = ((mpm[minCandModeIdx] - 1)      % mod) + 2;\n            mpm[4] = ((mpm[minCandModeIdx] + offset) % mod) + 2;\n            mpm[5] = ((mpm[maxCandModeIdx] - 1)      % mod) + 2;\n          }\n          else\n          {\n            mpm[3] = ((mpm[minCandModeIdx] + offset) % mod) + 2;\n            mpm[4] = ((mpm[minCandModeIdx] - 1)      % mod) + 2;\n            mpm[5] = ((mpm[maxCandModeIdx] + offset) % mod) + 2;\n          }\n        }\n        else if (leftIntraDir + aboveIntraDir >= 2)\n        {\n          mpm[0] = PLANAR_IDX;\n          mpm[1] = (leftIntraDir < aboveIntraDir) ? aboveIntraDir : leftIntraDir;\n          maxCandModeIdx = 1;\n          mpm[2] = ((mpm[maxCandModeIdx] + offset)     % mod) + 2;\n          mpm[3] = ((mpm[maxCandModeIdx] - 1)          % mod) + 2;\n          mpm[4] = ((mpm[maxCandModeIdx] + offset - 1) % mod) + 2;\n          mpm[5] = ( mpm[maxCandModeIdx]               % mod) + 2;\n        }\n      }\n    }\n    for (int i = 0; i < numMPMs; i++)\n    {\n      CHECK(mpm[i] >= NUM_LUMA_MODE, \"Invalid MPM\");\n    }\n    CHECK(numCand == 0, \"No candidates found\");\n    return numCand;\n  }\n}\n```\ngetPURestricted函数主要是根据位置获取PU\n\n```cpp\n\nconst PredictionUnit* CodingStructure::getPURestricted( const Position &pos, const PredictionUnit& curPu, const ChannelType _chType ) const\n{\n  const PredictionUnit* pu = getPU( pos, _chType );\n  // exists       same slice and tile                  pu precedes curPu in encoding order\n  //                                                  (thus, is either from parent CS in RD-search or its index is lower)\n  //存在 相同slice和Tile    PU在编码顺序中先于当前PU\n  //（因此，在RD搜索中是来自父CS的，或者其索引较低）\n  const bool wavefrontsEnabled = curPu.cu->slice->getSPS()->getEntropyCodingSyncEnabledFlag();\n  int ctuSizeBit = floorLog2(curPu.cs->sps->getMaxCUWidth());\n  int xNbY  = pos.x << getChannelTypeScaleX( _chType, curPu.chromaFormat );//相邻PU的左上角位置x\n  int xCurr = curPu.blocks[_chType].x << getChannelTypeScaleX( _chType, curPu.chromaFormat );//当前PU的左上角位置x\n  //判断相邻PU和当前PU是否在同一CTU中\n  bool addCheck = (wavefrontsEnabled && (xNbY >> ctuSizeBit) >= (xCurr >> ctuSizeBit) + 1 ) ? false : true;\n  if( pu && CU::isSameSliceAndTile( *pu->cu, *curPu.cu ) && ( pu->cs != curPu.cs || pu->idx <= curPu.idx ) && addCheck )\n  {\n    return pu;\n  }\n  else\n  {\n    return nullptr;\n  }\n}\n```\n\n## 3.5 色度分量亮度派生模式（Derived Mode，DM）技术\n针对色度预测模式编码，H266使用了DM模式，即直接使用对应位置的亮度预测查模式信息。","tags":["vvc"],"categories":["developer"]}]